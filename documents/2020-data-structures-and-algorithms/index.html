<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Data Structures and Algorithms</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Data Structures and Algorithms</h1>
</header>
<ul>
<li><a href="#pre-requisite-concepts">Pre-requisite Concepts</a>
<ul>
<li><a href="#asymptotic-runtime-analysis">Asymptotic Runtime Analysis</a>
<ul>
<li><a href="#big-o">Big O</a></li>
<li><a href="#amortized-analysis">Amortized Analysis</a></li>
<li><a href="#logarithmic-runtime">Logarithmic Runtime</a></li>
</ul></li>
<li><a href="#computational-complexity">Computational Complexity</a>
<ul>
<li><a href="#complexity-classes">Complexity Classes</a></li>
<li><a href="#np-problems">NP Problems</a></li>
<li><a href="#reductions">Reductions</a></li>
</ul></li>
<li><a href="#algorithm-design">Algorithm Design</a>
<ul>
<li><a href="#in-place-algorithm">In-place algorithm</a></li>
<li><a href="#spacetime-tradeoff">Space–time tradeoff</a></li>
<li><a href="#heuristics">Heuristics</a></li>
<li><a href="#hash-functions">Hash Functions</a></li>
<li><a href="#stack-vs.-heap-memory-allocation">Stack vs. Heap Memory Allocation</a></li>
</ul></li>
</ul></li>
<li><a href="#data-structures-and-adts">Data Structures and ADTs</a>
<ul>
<li><a href="#lists-and-arrays">Lists and Arrays</a>
<ul>
<li><a href="#list">List</a></li>
<li><a href="#arrays">Arrays</a></li>
<li><a href="#linked-lists">Linked Lists</a></li>
<li><a href="#self-organizing-lists">Self-Organizing Lists</a></li>
<li><a href="#skip-lists">Skip Lists</a></li>
</ul></li>
<li><a href="#stacks-and-queues">Stacks and Queues</a>
<ul>
<li><a href="#stacks">Stacks</a></li>
<li><a href="#queues">Queues</a></li>
<li><a href="#priority-queue">Priority Queue</a></li>
<li><a href="#indexed-priority-queue">Indexed Priority Queue</a></li>
<li><a href="#monotonic-queue-and-stack-deque">Monotonic Queue and Stack (Deque)</a></li>
</ul></li>
<li><a href="#hash-tables">Hash Tables</a>
<ul>
<li><a href="#dictionaries">Dictionaries</a></li>
<li><a href="#sets">Sets</a></li>
</ul></li>
<li><a href="#trees">Trees</a>
<ul>
<li><a href="#binary-trees">Binary Trees</a></li>
<li><a href="#binary-heaps">Binary Heaps</a></li>
<li><a href="#tries-prefix-trees">Tries (Prefix Trees)</a></li>
<li><a href="#suffix-treesarrays">Suffix Trees/Arrays</a></li>
<li><a href="#merkle-trees">Merkle Trees</a></li>
<li><a href="#kd-trees">Kd-Trees</a></li>
</ul></li>
<li><a href="#self-balancing-trees">Self-balancing Trees</a>
<ul>
<li><a href="#avl-trees">AVL Trees</a></li>
<li><a href="#redblack-trees">Red–black Trees</a></li>
<li><a href="#b-trees">B-Trees</a></li>
</ul></li>
<li><a href="#graphs">Graphs</a></li>
</ul></li>
<li><a href="#algorithms-and-techniques">Algorithms and Techniques</a>
<ul>
<li><a href="#sequence-search-and-sort">Sequence Search and Sort</a>
<ul>
<li><a href="#binary-search">Binary Search</a></li>
<li><a href="#bubble-sort">Bubble Sort</a></li>
<li><a href="#selection-sort">Selection Sort</a></li>
<li><a href="#insertion-sort">Insertion Sort</a></li>
<li><a href="#merge-sort">Merge Sort</a></li>
<li><a href="#quick-sort">Quick Sort</a></li>
<li><a href="#heap-sort">Heap Sort</a></li>
<li><a href="#counting-sort">Counting Sort</a></li>
<li><a href="#radix-sort">Radix Sort</a></li>
<li><a href="#timsort">Timsort</a></li>
</ul></li>
<li><a href="#array-analysis-methods">Array Analysis Methods</a>
<ul>
<li><a href="#two-pointer-technique">Two Pointer Technique</a></li>
<li><a href="#fast-and-slow-pointers">Fast and Slow Pointers</a></li>
<li><a href="#sliding-window-technique">Sliding Window Technique</a></li>
<li><a href="#single-pass-with-lookup-table">Single-pass with Lookup Table</a></li>
<li><a href="#range-operations-on-array">Range Operations on Array</a></li>
<li><a href="#kadanes-algorithm">Kadane’s Algorithm</a></li>
<li><a href="#prefix-sums-with-binary-search">Prefix Sums with Binary Search</a></li>
<li><a href="#merge-intervals">Merge Intervals</a></li>
</ul></li>
<li><a href="#string-analysis-methods">String Analysis Methods</a>
<ul>
<li><a href="#kmp-pattern-matching">KMP Pattern Matching</a></li>
<li><a href="#rabinkarp">Rabin–Karp</a></li>
<li><a href="#edit-distance">Edit Distance</a></li>
</ul></li>
<li><a href="#heap-use-cases">Heap Use Cases</a>
<ul>
<li><a href="#top-k-numbers">Top K Numbers</a></li>
<li><a href="#two-heaps-median-of-data-stream">Two Heaps (Median of Data Stream)</a></li>
</ul></li>
<li><a href="#tree-traversal">Tree Traversal</a></li>
<li><a href="#graph-traversal">Graph Traversal</a>
<ul>
<li><a href="#breadth-first-search">Breadth-First Search</a></li>
<li><a href="#depth-first-search">Depth-First Search</a></li>
<li><a href="#bidirectional-search">Bidirectional Search</a></li>
<li><a href="#dijkstras-shortest-path-algorithm">Dijkstra’s Shortest Path Algorithm</a></li>
<li><a href="#a">A*</a></li>
<li><a href="#bellman-ford-shortest-path-algorithm">Bellman-Ford Shortest Path Algorithm</a></li>
<li><a href="#floyd-warshall-all-pairs-shortest-path-algorithm">Floyd-Warshall All-Pairs Shortest Path Algorithm</a></li>
</ul></li>
<li><a href="#graph-analysis-methods">Graph Analysis Methods</a>
<ul>
<li><a href="#tarjans-strongly-connected-component-algorithm">Tarjan’s Strongly Connected Component Algorithm</a></li>
<li><a href="#prims-minimum-spanning-tree-algorithm">Prim’s Minimum Spanning Tree Algorithm</a></li>
<li><a href="#kruskals-minimum-spanning-tree-algorithm">Kruskal’s Minimum Spanning Tree Algorithm</a></li>
<li><a href="#topological-sort">Topological Sort</a></li>
</ul></li>
<li><a href="#recursive-problems">Recursive Problems</a>
<ul>
<li><a href="#the-dag-model">The DAG Model</a></li>
<li><a href="#backtracking">Backtracking</a></li>
<li><a href="#greedy-algorithms">Greedy Algorithms</a></li>
<li><a href="#dynamic-programming-memoization">Dynamic Programming &amp; Memoization</a></li>
</ul></li>
<li><a href="#numerical-problems">Numerical Problems</a>
<ul>
<li><a href="#bit-manipulation">Bit Manipulation</a></li>
</ul></li>
<li><a href="#combinatorial-problems">Combinatorial Problems</a>
<ul>
<li><a href="#permuations">Permuations</a></li>
<li><a href="#combinations">Combinations</a></li>
<li><a href="#cartesian-product">Cartesian Product</a></li>
<li><a href="#n-th-partial-sum">n-th Partial Sum</a></li>
<li><a href="#derangement">Derangement</a></li>
<li><a href="#fibonacci-numbers">Fibonacci Numbers</a></li>
<li><a href="#lattice-paths">Lattice Paths</a></li>
<li><a href="#catalan-numbers">Catalan Numbers</a></li>
<li><a href="#stars-and-bars">Stars and Bars</a></li>
</ul></li>
</ul></li>
<li><a href="#appendix">Appendix</a>
<ul>
<li><a href="#powers-of-2-table">Powers of 2 Table</a></li>
<li><a href="#array-sorting-algorithms-table">Array Sorting Algorithms Table</a></li>
<li><a href="#single-source-shortest-path-table">Single-Source Shortest Path Table</a></li>
<li><a href="#algorithm-optimization-checklist">Algorithm Optimization Checklist</a></li>
<li><a href="#whiteboard-interview-checklist">Whiteboard Interview Checklist</a></li>
</ul></li>
</ul>
<h1 id="pre-requisite-concepts">Pre-requisite Concepts</h1>
<h2 id="asymptotic-runtime-analysis">Asymptotic Runtime Analysis</h2>
<h3 id="big-o">Big O</h3>
<p>We can measure the growth rate of the time or space complexity of an algorithm using an upper bound (<span class="math inline">\(\mathcal{O}(f)\)</span>), lower bound (<span class="math inline">\(\Omega (f)\)</span>) or a tight bound (<span class="math inline">\(\Theta (f)\)</span>) on the best, worst or average case run time. When analysing an algorithm we typically use an upper bound on the worst case. <span class="math display">\[\mathcal{O}(1) \leq \mathcal{O}(\log n) \leq \mathcal{O}(n) \leq \mathcal{O}(n \log n) \leq \mathcal{O}(n^2) \leq  \mathcal{O}(2^n)  \leq \mathcal{O}(n!)\]</span></p>
<p>2</p>
<ul>
<li><p><span class="math inline">\(\mathcal{O}(1)\)</span> - constant time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(\log(n))\)</span> - logarithmic time</p></li>
<li><p><span class="math inline">\(\mathcal{O}((\log(n))c)\)</span> - polylogarithmic time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(n)\)</span> - linear time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(n^2)\)</span> - quadratic time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(n^c)\)</span> - polynomial time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(c^n)\)</span> - exponential time</p></li>
<li><p><span class="math inline">\(\mathcal{O}(n!)\)</span> - factorial time</p></li>
</ul>
<h3 id="amortized-analysis">Amortized Analysis</h3>
<p>If the cost of an action has high variance, i.e. its computation is often inexpensive but is occasionally expensive, we can capture its expected behaviour using an amortized time value. If we let <span class="math inline">\(T(n)\)</span> represent the amount of work the algorithm does on an input of size <span class="math inline">\(n\)</span>, An operation has amortized cost <span class="math inline">\(T(n)\)</span> if <span class="math inline">\(k\)</span> operations cost <span class="math inline">\(\leq k \cdot T(n)\)</span>. <span class="math inline">\(T(n)\)</span> being amortized roughly means <span class="math inline">\(T(n)\)</span> is averaged over all possible operations.</p>
<p>For example, a dynamic array will copy over elements to an array of double its size whenever an insert is called on an already full instance, otherwise it will simply insert the new element. For <span class="math inline">\(n\)</span> insertions, this happens on every <span class="math inline">\(2, 4, 8, ..., n\)</span> element. <span class="math display">\[T(n) = \mathcal{O}( n + \frac{n}{2} + \frac{n}{4} + \cdots + 1) 
        = \mathcal{O}(2n)\]</span> Therefore, <span class="math inline">\(n\)</span> insertions take <span class="math inline">\(\mathcal{O}(2n)\)</span> time and the amortized time for each insertion is <span class="math inline">\(\mathcal{O}(1)\)</span>.</p>
<p>A data structure realizing an amortized complexity of <span class="math inline">\(\mathcal{O}(f(n))\)</span> is less performant than one with a worst-case complexity is <span class="math inline">\(\mathcal{O}(f(n))\)</span>, since a very expensive operation might still occur, but it is better than an algorithm with an average-case complexity <span class="math inline">\(\mathcal{O}(f(n))\)</span>, since the amortized bound will achieve this average on any input.</p>
<h3 id="logarithmic-runtime">Logarithmic Runtime</h3>
<p>When encountering an algorithm in which the number of elements in the problem space is halved on each step, i.e. in a divide and conquer solution like binary search, the algorithm will likely have a <span class="math inline">\(\mathcal{O}(\log n)\)</span> or <span class="math inline">\(\mathcal{O}(n \log n)\)</span> run-time. We can think of <span class="math inline">\(\mathcal{O}(n \log n)\)</span> as doing <span class="math inline">\(\log n\)</span> work <span class="math inline">\(n\)</span> times.</p>
<p>Again, if we let <span class="math inline">\(T(n)\)</span> represent the amount of work the algorithm does on an input of size <span class="math inline">\(n\)</span>, <span class="math display">\[\begin{aligned}
        T(n) &amp;= T(n/2) + \Theta(1) \\
        &amp;=  T(n/4)+ \Theta(1) + \Theta(1) \\ 
        &amp;= \Theta(1) + \cdots + \Theta(1) \\
        &amp;= \Theta(\log n ) 
    \end{aligned}\]</span></p>
<p>When using Python’s standard library sort on an array, we can assume the running time will be <span class="math inline">\(\mathcal{O}(n \log n)\)</span>. See section on Timsort for further details.</p>
<h2 id="computational-complexity">Computational Complexity</h2>
<h3 id="complexity-classes">Complexity Classes</h3>
<p><span class="math display">\[P \subseteq NP \subseteq EXP \subseteq R\]</span></p>
<ol type="1">
<li><p><span class="math inline">\(P\)</span>: The set of problems that can be solved in polynomial time.</p></li>
<li><p><span class="math inline">\(NP\)</span>: The set of decision problems that can be solved in non-deterministic polynomial time via a “lucky” algorithm.</p></li>
<li><p><span class="math inline">\(EXP\)</span>: The set of problems that can be solved in exponential time.</p></li>
<li><p><span class="math inline">\(R\)</span>: The set of problems that can be solved in finite time.</p></li>
</ol>
<h3 id="np-problems">NP Problems</h3>
<p>Nondeterminsitic Polynomial (NP) problems follow a nondeterministic model in which an algorithm makes guesses and produce a binary output of YES or NO. These are the simplest interesting class of problems and are known as decision problems. A “lucky” algorithm can make guesses which are always correct without having to attempt all options. In other words, <span class="math inline">\(NP\)</span> is the set of decision problems with solutions that can be verified in polynomial time. This means that when an answer is YES, it can be proved and a polynomial-time algorithm can verify the proof.</p>
<p>P vs. NP asks whether generating proofs of solutions is harder than checking, i.e whether every problem whose solution can be quickly verified can also be solved quickly. NP-hard problems are those at least as hard as all NP problems. NP-hard problems need not be in NP; that is, they may not have solutions verifiable in polynomial time. NP-complete problems are a set of problems to each of which any other NP-problem can be reduced in polynomial time and whose solution may still be verified in polynomial time. In fact, NP-complete = NP <span class="math inline">\(\cap\)</span> NP-hard.</p>
<h3 id="reductions">Reductions</h3>
<p>A reduction is an algorithm for transforming one problem into another problem for which a solution or analysis already exists (instead of solving it from scratch). A sufficiently efficient reduction from one problem to another may be used to show that the second problem is at least as difficult as the first.</p>
<p>NP-complete problems are all interreducible using polynomial-time reductions (same difficulty). This implies that we can use reductions to prove NP-hardness. A one-call reduction is a polynomial time algorithm that constructs an instance of <span class="math inline">\(X\)</span> from an instance <span class="math inline">\(Y\)</span> so that their optimal values are equal, i.e. <span class="math inline">\(X\)</span> problem <span class="math inline">\(\implies\)</span> <span class="math inline">\(Y\)</span> problem <span class="math inline">\(\implies\)</span> <span class="math inline">\(Y\)</span> solution <span class="math inline">\(\implies\)</span> <span class="math inline">\(X\)</span> solution. Multicall reductions instead solve <span class="math inline">\(X\)</span> using free calls to <span class="math inline">\(Y\)</span> – in this sense, every algorithm reduces the problem and model of computation.</p>
<h2 id="algorithm-design">Algorithm Design</h2>
<h3 id="in-place-algorithm">In-place algorithm</h3>
<p>An in-place algorithm is an algorithm which transforms input using no auxiliary data structure, though a small amount of extra storage space is allowed for a constant number of auxiliary variables. The input is usually overwritten by the output (mutated) as the algorithm executes. An in-place algorithm updates input sequence only through replacement or swapping of elements.</p>
<h3 id="spacetime-tradeoff">Space–time tradeoff</h3>
<p>A space–time or time–memory trade-off is a case where an algorithm trades increased space usage with decreased time complexity. Here, space refers to the data storage consumed in performing a given task (RAM, HDD, etc), and time refers to the time consumed in performing a given task (computation time or response time).</p>
<h3 id="heuristics">Heuristics</h3>
<p>A heuristic is a technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution. This is achieved by trading optimality, completeness, accuracy, or precision for speed. In a way, it can be considered a shortcut.</p>
<h3 id="hash-functions">Hash Functions</h3>
<p>A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes. A good hash function satisfies two basic properties: it should be very fast to compute; it should minimize duplication of output values (<strong>collisions</strong>). For many use cases, it is useful for every hash value in the output range to be generated with roughly the same probability. Two of the most common hash algorithms are the MD5 (Message-Digest algorithm 5) and the SHA-1 (Secure Hash Algorithm).</p>
<h3 id="stack-vs.-heap-memory-allocation">Stack vs. Heap Memory Allocation</h3>
<p>The stack is the memory set aside as scratch space for a thread of execution. When a function is called, a block of fixed size is reserved on the top of the stack for local variables and some bookkeeping data. When that function returns, the block becomes freed for future use. The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed. This makes it really simple and fast to keep track of and access the stack; freeing a block from the stack is nothing more than adjusting one pointer. Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor’s cache, making it very fast.</p>
<p>The heap is memory set aside for dynamic allocation by the OS through the language runtime. Unlike the stack, there’s no enforced pattern to the allocation and deallocation of blocks from the heap. The size of the heap is set on application startup, but can grow as space is needed. This makes it much more complex to keep track of and access which parts of the heap are allocated or free at any given time. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe.</p>
<h1 id="data-structures-and-adts">Data Structures and ADTs</h1>
<p>An <strong>abstract data type (ADT)</strong> is a theoretical model of an entity and the set of operations that can be performed on that entity</p>
<p>A <strong>data structure</strong> is a value in a program which can be used to store and operate on data, i.e. it is a programmed implementation of an ADT.</p>
<p><strong>Contiguously-allocated structures</strong> are composed of single slabs of memory, and include arrays, matrices, heaps, and hash tables.</p>
<p><strong>Linked data structures</strong> are composed of distinct chunks of memory bound together by pointers, and include lists, trees, and graph adjacency lists. Recall, a pointer is a reference to a memory address which stores some data.</p>
<h2 id="lists-and-arrays">Lists and Arrays</h2>
<h3 id="list">List</h3>
<p>A list is an abstract data type that represents a countable number of ordered values, where the same value may occur more than once. Lists are a basic example of containers, as they contain other values. Their operations include the following,</p>
<ul>
<li><p><strong>isEmpty(L)</strong>: test whether or not the list is empty</p></li>
<li><p><strong>prepend(L, item)</strong>: prepend an entity to the list</p></li>
<li><p><strong>append(L, item)</strong>: append an entity to the list</p></li>
<li><p><strong>get(L, i)</strong>: access the element at a given index.</p></li>
<li><p><strong>head(L)</strong>: determine the first component of the list</p></li>
<li><p><strong>tail(L)</strong>: refer to the list consisting of all the components of a list except for its first (head).</p></li>
</ul>
<h3 id="arrays">Arrays</h3>
<p>An array is a data structure implementing a list ADT, consisting of a collection of elements (values or variables), each identified by at least one array index or key.</p>
<p>A <strong>bit array</strong> (a.k.a bit map) is a data structure which uses an array of 0’s and 1’s to compactly store information. An index <span class="math inline">\(j\)</span> with a value of 1 indicates the presence of an integer corresponding to <span class="math inline">\(j \in \mathbb Z\)</span>. When given a constraint on possible values that need to be stored and analyzed, we can initialize a bit array with a size of the max possible value and record frequencies directly in their corresponding index, eliminating the need to re-order an unsorted array or maintain a sorted order on every insertion. We can extend the bit array to store arbitrary integers, i.e. an int of value 3 in index 10 may indicate we’ve encountered 3 values of 10.</p>
<p>A <strong>dynamic array</strong> is a data structure that allocates all elements contiguously in memory and keeps a count of the current number of elements. If the space reserved for the dynamic array is exceeded, it is reallocated and (possibly) copied, which is an expensive operation. Though its amortized insertion cost is equal to a static array, <span class="math inline">\(\Theta(1)\)</span>. Python’s “List” data structure is a dynamic array.</p>
<p><em>Time Complexity of List operations</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Operation</strong></th>
<th style="text-align: left;"><strong>Average Case</strong></th>
<th style="text-align: left;"><strong>Amortized Worst Case</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Copy</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Append</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pop last</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Pop intermediate</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Insert</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Get Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Set Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Delete Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Iteration</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Get Slice</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Del Slice</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Set Slice</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k+n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k+n)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Extend</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Sort</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n\log n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n\log n)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Multiply</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(nk)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(nk)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">x in s</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">min(s), max(s)</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Get Length</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
</tbody>
</table>
<h3 id="linked-lists">Linked Lists</h3>
<p>A linked list is a data structure that represents a sequence of nodes. In a singly linked list each node maintains a pointer to the next node in the linked list. A doubly linked list gives each node pointers to both the next node and the previous node. Unlike an array, a linked list does not provide constant time access to a particular “index” within the list, i.e. to access the <span class="math inline">\(K\)</span>th index you will need to iterate through <span class="math inline">\(K\)</span> elements. The benefit of a linked list is that inserting and removing items from the beginning of the list can be done in constant time. For specific applications, this can be useful. Linked structures can have poor cache performance compared with arrays. Maintaining a sorted linked list is costly and not usually worthwhile since we cannot perform binary searches.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb1" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">class</span> ListNode:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, val<span class="op">=</span><span class="dv">0</span>, <span class="bu">next</span><span class="op">=</span><span class="va">None</span>):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>        <span class="va">self</span>.val <span class="op">=</span> val</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>        <span class="va">self</span>.<span class="bu">next</span> <span class="op">=</span> <span class="bu">next</span></span></code></pre></div>
<h3 id="self-organizing-lists">Self-Organizing Lists</h3>
<p>A self-organizing list is a list that reorders its elements based on some self-organizing heuristic to improve average access time. The aim of a self-organizing list is to improve efficiency of linear search by moving more frequently accessed items towards the head of the list. A self-organizing list achieves near constant time for element access in the best case and uses a reorganizing algorithm to adapt to various query distributions at runtime.</p>
<h3 id="skip-lists">Skip Lists</h3>
<p>As an alternative to balanced trees examined later, a hierarchy of sorted linked lists is maintained, where a random variable is associated to each element to decide whether it gets copied into the next highest list. This implies roughly <span class="math inline">\(\log n\)</span> lists, each roughly half as large as the one above it. A search starts in the smallest list. The search key lies in an interval between two elements, which is then explored in the next larger list. Each searched interval contains an expected constant number of elements per list, for a total expected <span class="math inline">\(\mathcal{O}(\log n)\)</span> query time. The primary benefits of skip lists are ease of analysis and implementation relative to balanced trees.</p>
<h2 id="stacks-and-queues">Stacks and Queues</h2>
<h3 id="stacks">Stacks</h3>
<p>A stack is an ADT container that uses last-in first-out (LIFO) ordering, i.e. the most recent item added to the stack is the first item to be removed. It supports the following operations:</p>
<ul>
<li><p><strong>pop()</strong>: Remove the top item from the stack.</p></li>
<li><p><strong>push(item)</strong>: Add an item to the top of the stack.</p></li>
<li><p><strong>peek()</strong>: Return the top of the stack.</p></li>
<li><p><strong>isEmpty()</strong>: Return true if and only if the stack is empty.</p></li>
</ul>
<p>Unlike an array, a stack does not offer constant-time access to the <span class="math inline">\(i\)</span>th item. However, it does allow constant time adds and removes as it doesn’t require shifting elements around. One case where stacks are often useful is in certain recursive algorithms where we need to push temporary data onto a stack as we recurse and then remove them as we backtrack (for example, because the recursive check failed). A stack offers an intuitive way to do this. A stack can also be used to implement a recursive algorithm iteratively which is what’s otherwise done in a function’s call stack.</p>
<h3 id="queues">Queues</h3>
<p>A queue is an ADT container that implements FIFO (first-in first-out) ordering, i.e. items are removed in the same order that they are added. It supports the following operations:</p>
<ul>
<li><p><strong>push(item)</strong>: Add an item to the end of the queue.</p></li>
<li><p><strong>popLeft()</strong>: Remove and return the first item in the queue.</p></li>
<li><p><strong>peek()</strong>: Return the top of the queue.</p></li>
<li><p><strong>isEmpty()</strong>: Return true if the queue is empty.</p></li>
</ul>
<p>One place where queues are often used is in breadth-first search or in implementing a cache. In breadth-first search we may use a queue to store a list of the nodes that we need to process. Each time we process a node, we add its adjacent nodes to the back of the queue. This allows us to process nodes in the order in which they are viewed.</p>
<p>A queue can be implemented with a linked list and moreover, they are essentially the same thing as long as items are added and removed from opposite sides.</p>
<p>The deque module (short for double-ended queue), provides a data structure which pops from or pushes to either side of the queue with the same <span class="math inline">\(\mathcal{O}(1)\)</span> performance.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb2" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="co"># Using a list </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>q <span class="op">=</span> []</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="cf">for</span> item <span class="kw">in</span> data:</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>    q.append(item) </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a><span class="cf">while</span> <span class="bu">len</span>(q):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    next_item <span class="op">=</span> queue.pop(<span class="dv">0</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>    <span class="bu">print</span>(next_item)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a><span class="co"># Using deque module </span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> deque </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>q <span class="op">=</span> deque() </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a><span class="cf">for</span> item <span class="kw">in</span> data:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>    q.append(item) </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a> </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a><span class="cf">while</span> <span class="bu">len</span>(q):</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>    next_item <span class="op">=</span> q.popleft() </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a>    <span class="bu">print</span>(next_item)</span></code></pre></div>
<p><em>Time Complexity of collections.deque operations</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Operation</strong></th>
<th style="text-align: left;"><strong>Average Case</strong></th>
<th style="text-align: left;"><strong>Amortized Worst Case</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Copy</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">append</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(O(1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">appendleft</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">pop</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">popleft</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">extend</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">extendleft</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">rotate</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(k)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">remove</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
</tbody>
</table>
<h3 id="priority-queue">Priority Queue</h3>
<p>A priority queue is an ADT container that retrieves items not by the insertion time (as in a stack or queue), nor by a key match (as in a dictionary), but instead retrieves items with the highest priority value. Priority queues provide more flexibility than simple sorting because they allow new elements to enter a system at arbitrary intervals. It is much more cost-effective to insert a new job into a priority queue than to re-sort everything on each such arrival. The basic priority queue supports three primary operations:</p>
<ul>
<li><p><strong>insert(Q, x)</strong>: Given an item x with key k, insert it into the priority queue Q.</p></li>
<li><p><strong>findMinimum(Q)</strong> or <strong>findMaximum(Q)</strong>: Return a pointer to the item whose key value is smaller (larger) than any other key in the priority queue Q.</p></li>
<li><p><strong>deleteMinimum(Q)</strong> or <strong>deleteMaximum(Q)</strong>: Remove the item from the priority queue Q whose key is minimum (maximum).</p></li>
</ul>
<p>There are several choices in which underlying data structures can be used for a basic priority queue implementation:</p>
<ol type="1">
<li><p>Sorted arrays are very efficient in both identifying the smallest element and deleting it by decrementing the top index. However, maintaining the total order makes inserting new elements slow. Sorted arrays are only suitable when there will be few insertions into the priority queue.</p></li>
<li><p>Binary heaps are the right answer when the upper bound on the number of items in your priority queue is known, since you must specify array size at creation time. Though this constraint can be mitigated by using dynamic arrays</p></li>
<li><p>Bounded height priority queue</p></li>
<li><p>Binary search trees make effective priority queues, since the smallest element is always the leftmost leaf, while the largest element is always the rightmost leaf. The min (max) is found by simply tracing down left (right) pointers until the next pointer is nil. Binary tree heaps prove most appropriate when you need other dictionary operations, or if you have an unbounded key range and do not know the maximum priority queue size in advance.</p></li>
<li><p>Fibonacci and pairing heaps. These complicated priority queues are designed to speed up decrease-key operations, where the priority of an item already in the priority queue is reduced. This arises, for example, in shortest path computations when we discover a shorter route to a vertex v than previously established.</p></li>
</ol>
<p>Note: The Queue.PriorityQueue module is a partial wrapper around the heapq module.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb3" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="co"># The Queue module</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="im">from</span> Queue <span class="im">import</span> PriorityQueue</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>q <span class="op">=</span> PriorityQueue()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a><span class="cf">for</span> item <span class="kw">in</span> data:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>    q.put((item.priority, item))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a><span class="cf">while</span> <span class="kw">not</span> q.empty():</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>    next_item <span class="op">=</span> q.get()</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>    <span class="bu">print</span>(next_item)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a><span class="co"># The heapq module</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a><span class="im">import</span> heapq</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true"></a>q <span class="op">=</span> []</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true"></a><span class="cf">for</span> item <span class="kw">in</span> data:</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true"></a>    heapq.heappush(q, (item.priority, item))</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true"></a><span class="cf">while</span> q:</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true"></a>    next_item <span class="op">=</span> heapq.heappop(q)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true"></a>    <span class="bu">print</span>(next_item)</span></code></pre></div>
<h3 id="indexed-priority-queue">Indexed Priority Queue</h3>
<p>An Indexed Priority Queue gives us the ability to change the priority of an element without having to go through all the elements. It can be thought of as a combination of a hash table, used for quick lookups of values, and a priority queue, to maintain a heap ordering.</p>
<h3 id="monotonic-queue-and-stack-deque">Monotonic Queue and Stack (Deque)</h3>
<p>This structure maintains an ordering so that its elements are either strictly increasing or strictly decreasing. It differs from a heap in that instead of re-ordering elements as they’re processed, it will discard previous numbers that do not follow the monotonic condition before appending a new number.</p>
<p>It can be useful for finding the index of next larger or smaller number given an unordered list of numbers. In some application we might further need to remove element from the front. Thus a double-ended queue (deque from collections) can be used. In an increasing queue, we find the first element smaller than current, either in the left (from pushing in) or in the right (from popping out). In a decreasing queue we find the first element larger than current, either in the left (from pushing in) or in the right (from popping out).</p>
<p>A monotonic queue can also useful for implementing a variant of the sliding window. See section for example.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb4" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="im">import</span> collections</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="kw">def</span> increasing_queue(A):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>    queue <span class="op">=</span> collections.deque()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>    smaller_to_left, smaller_to_right <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(A), [<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(A)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>    <span class="cf">for</span> i,v <span class="kw">in</span> <span class="bu">enumerate</span>(A):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>        <span class="cf">while</span> queue <span class="kw">and</span> A[queue[<span class="op">-</span><span class="dv">1</span>]] <span class="op">&gt;=</span> v: </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>            smaller_to_right[queue.pop()] <span class="op">=</span> v </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>        <span class="cf">if</span> queue:  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a>            smaller_to_left[i] <span class="op">=</span> A[queue[<span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a>        queue.append(i)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a>    <span class="cf">return</span> smaller_to_left, smaller_to_right</span></code></pre></div>
<h2 id="hash-tables">Hash Tables</h2>
<p>A hash table is a data structure that maps keys to values for highly efficient lookup. There are a number of ways of implementing this. First, we will describe a simple but common implementation known as <strong>separate chaining</strong>. In this implementation, we use an array of linked lists and a hash code function. To insert a key (which might be a string or essentially any other data type) and value, we do the following:</p>
<ol type="1">
<li><p>First, compute the key’s hash code, which will usually be an <em>int</em> or <em>long</em>. Note that two different keys could have the same hash code, as there may be an infinite number of keys and a finite number of hash codes.</p></li>
<li><p>Then, map the hash code to an index in the array. This could be done with something like <span class="math inline">\(hash(key)\mod array\_length\)</span>. Two different hash codes could map to the same index.</p></li>
<li><p>At this index, there is a linked list of keys and values. Store the key and value in this index. We must use a linked list because of collisions: you could have two different keys with the same hash code, or two different hash codes that map to the same index.</p></li>
</ol>
<p>To retrieve the value pair by its key, you repeat this process. Compute the hash code from the key, and then compute the index from the hash code. Then, search through the linked list for the value with this key. If the number of collisions is very high, the worst case runtime is <span class="math inline">\(\mathcal{O}(n)\)</span>, where <span class="math inline">\(n\)</span> is the number of keys. However, we generally assume a good implementation that keeps collisions to a minimum, in which case the lookup time is <span class="math inline">\(\mathcal{O}(1)\)</span>. Alternatively, we can implement the hash table with a balanced binary search tree. This gives us an <span class="math inline">\(\mathcal{O}(\log n)\)</span> lookup time. The advantage of this is potentially using less space, since we no longer allocate a large array. We can also iterate through the keys in order, which can be useful sometimes.</p>
<p>The other strategy used to resolve collisions is to require each array element to contain only one key, but to also allow keys to be mapped to alternate indices when their original spot is already occupied. This is known as <strong>open addressing</strong>. In this type of hashing, we have a parameterized hash function <span class="math inline">\(h\)</span> that takes two arguments, a key and a positive integer. Searching or <strong>probing</strong> for an item requires examining not just one spot, but many spots until either we find the key, or reach a None value. After we delete an item, we replace it with a special value Deleted, rather than simply None. This way, the Search algorithm will not halt when it reaches an index that belonged to a deleted key.</p>
<p>The simplest implementation of open addressing is <strong>linear probing</strong>: start at a given hash value and then keep adding some fixed offset to the index until an empty spot is found. The main problem with linear probing is that the hash values in the middle of a cluster will follow the exact same search pattern as a hash value at the beginning of the cluster. As such, more and more keys are absorbed into this long search pattern as clusters grow. We can solve this problem using <strong>quadratic probing</strong>, which causes the offset between consecutive indices in the probe sequence to increase as the probe sequence is visited. <strong>Double hashing</strong> resolves the problem of a form of clustering occurs where if many items have the same initial hash value, they still follow the exact same probe sequence. It does this by using a hash function for both the initial value and its offset.</p>
<p>A useful hash function for strings is, <span class="math display">\[H(S,j) = \sum_{i=0}^{m-1} \alpha^{m-(i+1)} \cdot char(s_{i+j}) \mod m\]</span> where <span class="math inline">\(\alpha\)</span> is the size of the alphabet and <span class="math inline">\(char(x)\)</span> is the ASCII character code. This hash function has the useful property allowing hashes of successive m-character windows of a string to be computed in constant time instead of <span class="math inline">\(\mathcal{O}(m)\)</span>. <span class="math display">\[H(S, j+1) = (H(S,j) - \alpha^{m-1}char(s_j))\alpha + s_{j+m}\]</span></p>
<h3 id="dictionaries">Dictionaries</h3>
<p>The dictionary data type (a.k.a. hash table or hash map) permits access to data items based on its content. You insert an item into a dictionary so you can retrieve it when you need it.</p>
<p>Python dicts use open addressing to resolve hash collisions which uses random probing in which the next slot is picked in a pseudo random order. The entry is then added to the first empty slot.</p>
<p>The primary operations a dictionary supports are:</p>
<ul>
<li><p><strong>search(D, k)</strong> – Given a search key <span class="math inline">\(k\)</span>, return a pointer to the element in dictionary <span class="math inline">\(D\)</span> whose key value is <span class="math inline">\(k\)</span>, if one exists.</p></li>
<li><p><strong>insert(D, x)</strong> – Given a data item <span class="math inline">\(x\)</span>, add it to the set in the dictionary <span class="math inline">\(D\)</span>.</p></li>
<li><p><strong>delete(D, x)</strong> – Given a pointer to a given data item <span class="math inline">\(x\)</span> in the dictionary <span class="math inline">\(D\)</span>, remove it from <span class="math inline">\(D\)</span>.</p></li>
<li><p><strong>max(D)</strong> or <strong>min(D)</strong> – Retrieve the item with the largest (or smallest) key from <span class="math inline">\(D\)</span>. This enables the dictionary to serve as a priority queue.</p></li>
<li><p><strong>predecessor(D, k)</strong> or <strong>successor(D, k)</strong> – Retrieve the item from <span class="math inline">\(D\)</span> whose key is immediately before (or after) <span class="math inline">\(k\)</span> in sorted order. These enable us to iterate through the elements of the data structure.</p></li>
</ul>
<p><em>Time Complexity of dict operations</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Operation</strong></th>
<th style="text-align: left;"><strong>Average Case</strong></th>
<th style="text-align: left;"><strong>Amortized Worst Case</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">k in d</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Copy</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Get Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Set Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Delete Item</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Iteration[2]</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
</tbody>
</table>
<h3 id="sets">Sets</h3>
<p>In mathematical terms, a set is an unordered collection of unique objects drawn from a fixed universal set. A hash set implements the set ADT using a hash table. Sorted order turns the problem of finding the union or intersection of two subsets into a linear-time operation, just sweep from left to right and see what you are missing. It makes possible element searching in sublinear time. Finally, printing the elements of a set in a canonical order paradoxically reminds us that order really doesn’t matter.</p>
<p>If each subset contains exactly two elements, they can be thought of as edges in a graph whose vertices represent the universal set. A system of subsets with no restrictions on the cardinality of its members is called a hypergraph.</p>
<ol type="1">
<li><p>Test whether <span class="math inline">\(u_i \in S_j\)</span></p></li>
<li><p>Compute the union or intersection of <span class="math inline">\(S_i\)</span> and <span class="math inline">\(S_j\)</span></p></li>
<li><p>Insert or delete members of <span class="math inline">\(S\)</span></p></li>
</ol>
<p>Although sets are commonly implemented with hash tables, other data structures that can be used:</p>
<ol type="1">
<li><p>Containers or dictionaries – A subset can also be represented using a linked list, array, or dictionary containing exactly the elements in the subset.</p></li>
<li><p>Bit vectors – An n-bit vector or array can represent any subset <span class="math inline">\(S\)</span> on a universal set <span class="math inline">\(U\)</span> containing <span class="math inline">\(n\)</span> items. Bit <span class="math inline">\(i\)</span> will be 1 if <span class="math inline">\(i \in S\)</span>, and <span class="math inline">\(0\)</span> if not.</p></li>
<li><p>Bloom filters – We can emulate a bit vector in the absence of a fixed universal set by hashing each subset element to an integer from <span class="math inline">\(0\)</span> to <span class="math inline">\(n\)</span> and setting the corresponding bit.</p></li>
</ol>
<p><em>Time Complexity of set operations</em></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Operation</strong></th>
<th style="text-align: left;"><strong>Average Case</strong></th>
<th style="text-align: left;"><strong>Amortized Worst Case</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">x in s</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(1)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Union</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(s)+len(t))\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Intersection</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(min(len(s), len(t))\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(s) * len(t))\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Multiple intersection</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(n-1)*\mathcal{O}(max(len(s_i)))\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Difference</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(s))\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Difference Update</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(t))\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Symmetric Difference</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(s))\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(s) * len(t))\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Symmetric Difference Update</td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(t))\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\mathcal{O}(len(t) * len(s))\)</span></td>
</tr>
</tbody>
</table>
<h2 id="trees">Trees</h2>
<p>A tree is an ADT composed of nodes such that there is a root node with zero or more child nodes where each child node also has zero or more child nodes and can be recursively defined as a root node of a sub-tree. Since there are no edges between sibling nodes, a tree cannot contain cycles. Furthermore, nodes can be given a particular order, can have any data type as values, and they may or may not have links back to their parent nodes.</p>
<h3 id="binary-trees">Binary Trees</h3>
<p>A binary tree is a tree in which each node has up to two children. A <strong>binary search tree</strong> is a binary tree in which every node <span class="math inline">\(n\)</span> follows a specific ordering property: all left descendants <span class="math inline">\(\leq n &lt;\)</span> all right descendants. A <strong>complete</strong> binary tree is a binary tree in which every level of the tree is filled, except for perhaps the last level and all of the nodes in the bottom level are as far to the left as possible. A <strong>full</strong> binary tree is a binary tree in which every node has either zero or two children. A <strong>perfect</strong> binary tree is one that is both full and complete.</p>
<p>A complete tree with <span class="math inline">\(n\)</span> nodes has <span class="math inline">\(\lceil \log n \rceil\)</span> height. There is no ambiguity about where the “empty” spots in a complete tree are so we do not need to use up space to store references between nodes, as we do in a standard binary tree implementation. This means that we can store its nodes inside an zero-indexed array. For a node corresponding to index <span class="math inline">\(i\)</span>, its left child is stored at index <span class="math inline">\(2i + 1\)</span>, and its right child is stored at index <span class="math inline">\(2i + 2\)</span>. Going backwards, we can also deduce that the parent of index <span class="math inline">\(i\)</span> (when <span class="math inline">\(i &gt; 1\)</span>) is stored at index <span class="math inline">\(\lceil (i-1)/2 \rceil\)</span>.</p>
<p>Note, A full binary tree with <span class="math inline">\(n\)</span> leaves has <span class="math inline">\(n - 1\)</span> internal nodes. Then the number of unique rooted full binary tree with <span class="math inline">\(n + 1\)</span> leaf nodes, equivalently <span class="math inline">\(n\)</span> internal node, can be counted via the <span class="math inline">\(nth\)</span> Catalan number, <span class="math inline">\(C_n\)</span>. View section on Catalan numbers for the formula and implementation code.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb5" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co"># n-ary tree using dictionary</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a><span class="co">## a tree is a dict whose default values are trees. </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>tree <span class="op">=</span> <span class="kw">lambda</span>: defaultdict(tree)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a><span class="co"># Object-oriented binary tree</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a><span class="kw">class</span> TreeNode:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, val<span class="op">=</span><span class="dv">0</span>, left<span class="op">=</span><span class="va">None</span>, right<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a>        <span class="va">self</span>.val <span class="op">=</span> val</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>        <span class="va">self</span>.left <span class="op">=</span> left</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>        <span class="va">self</span>.right <span class="op">=</span> right</span></code></pre></div>
<h3 id="binary-heaps">Binary Heaps</h3>
<p>The <strong>heap property</strong> states that the key stored in each node is either greater than or equal to or less than or equal to the keys in the node’s children, according to some total order. A <strong>min-heap</strong> is a complete binary tree (filled other than the rightmost elements on the last level) where each node is smaller than its children. The root, therefore, is the minimum element in the tree. The converse holds for a <strong>max-heap</strong>. We have two key operations on a heap:</p>
<ul>
<li><p><strong>insert(x)</strong>: When we insert into a min-heap, we always start by inserting the element at the bottom. We insert at the rightmost spot so as to maintain the complete tree property. Then, we maintain the heap property by swapping the new element with its parent until we find an appropriate spot for the element. We essentially bubble up the minimum element. This takes <span class="math inline">\(\mathcal{O}(\log n)\)</span> time, where <span class="math inline">\(n\)</span> is the number of nodes in the heap.</p></li>
<li><p><strong>findMin()</strong> or <strong>findMax()</strong>: Finding the minimum element of a min-heap is inexpensive since it will always be at the top. The challenging part is how to remove it while maintaining the heap property. First, we remove the minimum element and swap it with the last element in the heap (the bottommost, rightmost element). Then, we bubble down this element, swapping it with one of its children until the heap property is restored. This algorithm will also take <span class="math inline">\(\mathcal{O}( \log n)\)</span> time.</p></li>
</ul>
<p>A heap will be better at findMin/findMax (<span class="math inline">\(\mathcal{O}(1)\)</span>), while a BST is performant at all finds (<span class="math inline">\(\mathcal{O}(\log n)\)</span>). A heap is especially good at basic ordering and keeping track of max and mins.</p>
<p>Note, heapq creates a min-heap by default. To create a max-heap, you will need to invert value before storing and after retrieving. Alternatively, you can define a class to wrap the module and override and invert the comparison method.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb6" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="co"># Using heapq module</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a><span class="im">import</span> heapq</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>items <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>]    </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a><span class="co">## Min heap</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true"></a>min_heap <span class="op">=</span> heapq.heapify(items)            </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true"></a>min_item <span class="op">=</span> heapq.heappop(min_heap)      </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true"></a><span class="kw">class</span> MinHeap(<span class="bu">object</span>):</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): <span class="va">self</span>.h <span class="op">=</span> []</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true"></a>  <span class="kw">def</span> heappush(<span class="va">self</span>, x): heapq.heappush(<span class="va">self</span>.h, x)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true"></a>  <span class="kw">def</span> heappop(<span class="va">self</span>): <span class="cf">return</span> heapq.heappop(<span class="va">self</span>.h)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i): <span class="cf">return</span> <span class="va">self</span>.h[i]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.h)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true"></a><span class="co">## Max heap</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true"></a>max_heap <span class="op">=</span> heapq._heapify_max(items)       </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true"></a>max_item <span class="op">=</span> heapq._heappop_max(max_heap) </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true"></a><span class="kw">class</span> MaxHeapObj(<span class="bu">object</span>):</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, val): <span class="va">self</span>.val <span class="op">=</span> val</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__lt__</span>(<span class="va">self</span>, other): </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;Invert comparison logic&quot;&quot;&quot;</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true"></a>    <span class="cf">return</span> <span class="va">self</span>.val <span class="op">&gt;</span> other.val</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true"></a>  </span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true"></a><span class="kw">class</span> MaxHeap(MinHeap):</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true"></a>  <span class="kw">def</span> heappush(<span class="va">self</span>, x): heapq.heappush(<span class="va">self</span>.h, MaxHeapObj(x))</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true"></a>  <span class="kw">def</span> heappop(<span class="va">self</span>): <span class="cf">return</span> heapq.heappop(<span class="va">self</span>.h).val</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i): <span class="cf">return</span> <span class="va">self</span>.h[i].val</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true"></a><span class="co"># Max heap full implementation</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true"></a><span class="kw">class</span> MaxHeap:</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, items<span class="op">=</span>[]):</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true"></a>        <span class="va">self</span>.heap <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true"></a>        <span class="cf">for</span> i <span class="kw">in</span> items:</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true"></a>            <span class="va">self</span>.heap.append(i)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true"></a>            <span class="va">self</span>.__floatUp(<span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true"></a>    <span class="kw">def</span> push(<span class="va">self</span>, data):</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true"></a>        <span class="va">self</span>.heap.append(data)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true"></a>        <span class="va">self</span>.__floatUp(<span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true"></a>    <span class="kw">def</span> peek(<span class="va">self</span>):</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true"></a>        <span class="cf">if</span> <span class="va">self</span>.heap[<span class="dv">1</span>]:</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">self</span>.heap[<span class="dv">1</span>]</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true"></a>    <span class="kw">def</span> pop(<span class="va">self</span>):</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">&gt;</span> <span class="dv">2</span>:</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true"></a>            <span class="va">self</span>.__swap(<span class="dv">1</span>, <span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true"></a>            maxVal <span class="op">=</span> <span class="va">self</span>.heap.pop()</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true"></a>            <span class="va">self</span>.__bubbleDown(<span class="dv">1</span>)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true"></a>        <span class="cf">elif</span> <span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true"></a>            maxVal <span class="op">=</span> <span class="va">self</span>.heap.pop()</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true"></a>            maxVal <span class="op">=</span> <span class="va">False</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true"></a>        <span class="cf">return</span> maxVal</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true"></a></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true"></a>    <span class="kw">def</span> __swap(<span class="va">self</span>, i, j):</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true"></a>        <span class="va">self</span>.heap[i], <span class="va">self</span>.heap[j] <span class="op">=</span> <span class="va">self</span>.heap[j], <span class="va">self</span>.heap[i]</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true"></a></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true"></a>    <span class="kw">def</span> __floatUp(<span class="va">self</span>, index):</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true"></a>        parent <span class="op">=</span> index<span class="op">//</span><span class="dv">2</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true"></a>        <span class="cf">if</span> index <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true"></a>            <span class="cf">return</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true"></a>        <span class="cf">elif</span> <span class="va">self</span>.heap[index] <span class="op">&gt;</span> <span class="va">self</span>.heap[parent]:</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true"></a>            <span class="va">self</span>.__swap(index, parent)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true"></a>            <span class="va">self</span>.__floatUp(parent)</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true"></a>    <span class="kw">def</span> __bubbleDown(<span class="va">self</span>, index):</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true"></a>        left <span class="op">=</span> index <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true"></a>        right <span class="op">=</span> index <span class="op">*</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true"></a>        largest <span class="op">=</span> index</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">&gt;</span> left <span class="kw">and</span> <span class="va">self</span>.heap[largest] <span class="op">&lt;</span> <span class="va">self</span>.heap[left]:</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true"></a>            largest <span class="op">=</span> left</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.heap) <span class="op">&gt;</span> right <span class="kw">and</span> <span class="va">self</span>.heap[largest] <span class="op">&lt;</span> <span class="va">self</span>.heap[right]:</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true"></a>            largest <span class="op">=</span> right</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true"></a>        <span class="cf">if</span> largest <span class="op">!=</span> index:</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true"></a>            <span class="va">self</span>.__swap(index, largest)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true"></a>            <span class="va">self</span>.__bubbleDown(largest)</span></code></pre></div>
<h3 id="tries-prefix-trees">Tries (Prefix Trees)</h3>
<p>A trie is a variant of an n-ary tree in which alphanumeric characters are stored at each node. Each path down the tree may represent a word. The * nodes (sometimes called "null nodes") are often used to indicate complete words. The actual implementation of these * nodes might be a special type of child (i.e. a TerminatingTrieNode class which inherits from TrieNode) or we can use a boolean flag. A node in a trie could have anywhere from 1 through size of alphabet + 1 children (or, 0 through size of alphabet if a boolean flag is used instead of a * node).</p>
<p>The complexity of creating a trie is <span class="math inline">\(\mathcal{O}(|W| L)\)</span>, where <span class="math inline">\(W\)</span> is the number of words, and <span class="math inline">\(L\)</span> is an average length of the word: you need to perform <span class="math inline">\(L\)</span> lookups on average for each of the <span class="math inline">\(W\)</span> words in the set. Same goes for looking up words later: you perform <span class="math inline">\(L\)</span> steps for each of the <span class="math inline">\(W\)</span> words.</p>
<p>Very commonly, a trie is used to store the entire English language for quick prefix lookups. A trie can check if a string is a valid prefix in <span class="math inline">\(\mathcal{O}(K)\)</span> time, where <span class="math inline">\(K\)</span> is the length of the string. Many problems involving lists of valid words leverage a trie as an optimization.</p>
<p>To get matched suggestions, it helps to store the word along with the end indicator. We can then search the trie up to the prefix end and perform a recursive DFS to all word end points while appending the results to an array of suggestions. To handle misspellings, a function considers four types of edits: deletion (remove one letter), a transposition (swap two adjacent letters), a replacement (change one letter to another) or an insertion (add a letter). The edit function returns a list of words within a max <span class="math inline">\(N\)</span> edits from the specified word that exist in a dictionary of known words. We can then find suggestions with DFS as before.</p>
<p>Note, most methods in the trie follow a similar traversal pattern, create a pointer to the root of the tree, iterate over characters of a given word, check if the character is not in the current pointers children and then move the pointer forward to the corresponding child.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb7" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="im">import</span> collections</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a><span class="kw">class</span> TrieNode:</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a>        <span class="va">self</span>.word <span class="op">=</span> <span class="va">False</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a>        <span class="va">self</span>.children <span class="op">=</span> {}</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a><span class="kw">class</span> Trie:</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a>        <span class="va">self</span>.root <span class="op">=</span> TrieNode()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a>    <span class="kw">def</span> insert(<span class="va">self</span>, word):</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true"></a>        node <span class="op">=</span> <span class="va">self</span>.root</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true"></a>        <span class="cf">for</span> char <span class="kw">in</span> word:</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true"></a>            <span class="cf">if</span> char <span class="kw">not</span> <span class="kw">in</span> node.children:</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true"></a>                node.children[char] <span class="op">=</span> TrieNode()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true"></a>            node <span class="op">=</span> node.children[char]</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true"></a>        node.word <span class="op">=</span> <span class="va">True</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true"></a>    <span class="kw">def</span> search(<span class="va">self</span>, word):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true"></a>        node <span class="op">=</span> <span class="va">self</span>.root</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true"></a>        <span class="cf">for</span> char <span class="kw">in</span> word:</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true"></a>            <span class="cf">if</span> char <span class="kw">not</span> <span class="kw">in</span> node.children:</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true"></a>                <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true"></a>            node <span class="op">=</span> node.children[char]</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true"></a>        <span class="cf">return</span> node.word</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true"></a>    <span class="kw">def</span> startsWith(<span class="va">self</span>, prefix):</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true"></a>        node <span class="op">=</span> <span class="va">self</span>.root</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true"></a>        <span class="cf">for</span> char <span class="kw">in</span> prefix:</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true"></a>            <span class="cf">if</span> char <span class="kw">not</span> <span class="kw">in</span> node.children:</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true"></a>                <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true"></a>            node <span class="op">=</span> node.children[char]</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true"></a>    </span></code></pre></div>
<h3 id="suffix-treesarrays">Suffix Trees/Arrays</h3>
<p>A special kind of trie, called a suffix tree, can be used to index all suffixes in a text in order to carry out fast full text searches. The construction of such a tree for the string <span class="math inline">\(S\)</span> takes linear time and space relative to the length of <span class="math inline">\(S\)</span>. A suffix tree is basically like a search trie: there is a root node, edges going out of it leading to new nodes, and further edges going out of those, and so forth. Unlike in a search trie, the edge labels are not single characters. Instead, each edge is labeled using a pair of integers: [from, to], which are pointers into the text. In this sense, each edge carries a string label of arbitrary length, but takes only <span class="math inline">\(\mathcal{O}(1)\)</span> space (two pointers).</p>
<p>Some example use cases are as follows:</p>
<ul>
<li><p>Find all occurrences of <span class="math inline">\(q\)</span> as a substring of <span class="math inline">\(S\)</span>: In collapsed suffix trees, it takes <span class="math inline">\(\mathcal{O}(|q| + k)\)</span> time to find the <span class="math inline">\(k\)</span> occurrences of <span class="math inline">\(q\)</span> in <span class="math inline">\(S\)</span>.</p></li>
<li><p>Locating a substring if a certain number of mistakes or edits are allowed</p></li>
<li><p>Locating matches for a regular expression pattern</p></li>
<li><p>Finding Longest common substring to a set of strings in linear-time</p></li>
<li><p>Find the longest palindrome in <span class="math inline">\(S\)</span></p></li>
</ul>
<p>Storing a string’s suffix tree typically requires significantly more space than storing the string itself. Observe that most of the nodes in a trie-based suffix tree occur on simple paths between branch nodes in the tree. Each of these simple paths corresponds to a substring of the original string. By storing the original string in an array and collapsing each such path into a single edge, we have all the information of the full suffix tree in only <span class="math inline">\(\mathcal{O}(n)\)</span> space. The label for each edge is described by the starting and ending array indices representing the substring.</p>
<p>The suffix tree for the string <span class="math inline">\(S\)</span> of length <span class="math inline">\(n\)</span> is defined as a tree such that:</p>
<ol type="1">
<li><p>The tree has exactly <span class="math inline">\(n\)</span> leaves numbered from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>.</p></li>
<li><p>Except for the root, every internal node has at least two children.</p></li>
<li><p>Each edge is labelled with a non-empty substring of <span class="math inline">\(S\)</span>.</p></li>
<li><p>No two edges starting out of a node can have string-labels beginning with the same character.</p></li>
<li><p>The string obtained by concatenating all the string-labels found on the path from the root to leaf <span class="math inline">\(i\)</span> spells out suffix <span class="math inline">\(S[i \cdots n]\)</span>, for <span class="math inline">\(i\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>.</p></li>
</ol>
<p>Suffix arrays do most of what suffix trees do, while using roughly four times less memory. They are also easier to implement. A suffix array is, in principle, just an array that contains all the <span class="math inline">\(n\)</span> suffixes of <span class="math inline">\(S\)</span> in sorted order. Thus a binary search of this array for string <span class="math inline">\(q\)</span> suffices to locate the prefix of a suffix that matches <span class="math inline">\(q\)</span>, permitting an efficient substring search in <span class="math inline">\(O(\log n)\)</span> string comparisons. With the addition of an index specifying the common prefix length of all bounding suffixes, only <span class="math inline">\(\log n+|q|\)</span> character comparisons need be performed on any query, since we can identify the next character that must be tested in the binary search.</p>
<p>In a suffix array, a suffix is represented completely by its unique starting position (from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>) and read off as needed using a single reference copy of the input string. Some care must be taken to construct suffix arrays efficiently, however, since there are <span class="math inline">\(O(n^2)\)</span> characters in the strings being sorted. One solution is to first build a suffix tree, then perform an in-order traversal of it to read the strings off in sorted order. However, more recent breakthroughs have lead to space/time efficient algorithms for constructing suffix arrays directly.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb8" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="im">from</span> itertools <span class="im">import</span> zip_longest, islice</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a><span class="kw">def</span> to_int_keys(l):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a>    seen <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>    ls <span class="op">=</span> []</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a>    <span class="cf">for</span> e <span class="kw">in</span> l:</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a>        <span class="cf">if</span> <span class="kw">not</span> e <span class="kw">in</span> seen:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a>            ls.append(e)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a>            seen.add(e)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a>    ls.sort()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a>    index <span class="op">=</span> {v: i <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(ls)}</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a>    <span class="cf">return</span> [index[v] <span class="cf">for</span> v <span class="kw">in</span> l]</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a><span class="kw">def</span> suffix_array(s):</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true"></a><span class="co">    suffix array of s, TC: O(n * log(n)^2)</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true"></a>    n <span class="op">=</span> <span class="bu">len</span>(s)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true"></a>    k <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true"></a>    line <span class="op">=</span> to_int_keys(s)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true"></a>    <span class="cf">while</span> <span class="bu">max</span>(line) <span class="op">&lt;</span> n <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true"></a>        line <span class="op">=</span> to_int_keys(</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true"></a>            [a <span class="op">*</span> (n <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> b <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true"></a>             <span class="cf">for</span> (a, b) <span class="kw">in</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true"></a>             zip_longest(line, islice(line, k, <span class="va">None</span>),</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true"></a>                         fillvalue<span class="op">=-</span><span class="dv">1</span>)])</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true"></a>        k <span class="op">&lt;&lt;=</span> <span class="dv">1</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true"></a>    <span class="cf">return</span> line</span></code></pre></div>
<h3 id="merkle-trees">Merkle Trees</h3>
<p>A <strong>hash tree</strong> or Merkle tree is a tree in which every leaf node is labelled with the cryptographic hash of a data block, and every non-leaf node is labelled with the cryptographic hash of the labels of its child nodes. Hash trees allow efficient and secure verification of the contents of large data structures. Hash trees are a generalization of hash lists and hash chains.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb9" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a><span class="im">from</span> hashlib <span class="im">import</span> sha256</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true"></a><span class="kw">def</span> <span class="bu">hash</span>(x):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true"></a>    S <span class="op">=</span> sha256()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true"></a>    S.update(x)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true"></a>    <span class="cf">return</span> S.hexdigest()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true"></a><span class="kw">def</span> merkle(node):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true"></a>    <span class="cf">if</span> <span class="kw">not</span> node:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true"></a>        <span class="cf">return</span> <span class="st">&#39;#&#39;</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true"></a>    m_left <span class="op">=</span> merkle(node.left)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true"></a>    m_right <span class="op">=</span> merkle(node.right)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true"></a>    node.merkle <span class="op">=</span> <span class="bu">hash</span>(m_left <span class="op">+</span> <span class="bu">str</span>(node.val) <span class="op">+</span> m_right)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true"></a>    <span class="cf">return</span> node.merkle</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true"></a><span class="co"># Two trees are identical if the hash of their roots are equal (except for collisions)</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true"></a><span class="kw">def</span> isSubtree(s, t):</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true"></a>    merkle(s)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true"></a>    merkle(t)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true"></a>    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true"></a>        <span class="cf">if</span> <span class="kw">not</span> node:</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true"></a>        <span class="cf">return</span> (node.merkle <span class="op">==</span> t.merkle <span class="kw">or</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true"></a>                dfs(node.left) <span class="kw">or</span> dfs(node.right))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true"></a>    <span class="cf">return</span> dfs(s)</span></code></pre></div>
<h3 id="kd-trees">Kd-Trees</h3>
<p>Kd-trees and related spatial data structures hierarchically partition k-dimensional space into a small number of cells, each containing a few representatives from an input set of points. This provides a fast way to access any object by position. We traverse down the hierarchy until we find the smallest cell containing it, and then scan through the objects in this cell to identify the right one.</p>
<p>Typical algorithms construct kd-trees by partitioning point sets. Ideally, this plane equally partitions the subset of points into left/right (or up/down) subsets. Partitioning stops after <span class="math inline">\(\log n\)</span> levels, with each point in its own leaf cell. Each box-shaped region is defined by <span class="math inline">\(2k\)</span> planes, where <span class="math inline">\(k\)</span> is the number of dimensions. Useful applications are as follows:</p>
<ul>
<li><p>Point location – To identify which cell a query point <span class="math inline">\(q\)</span> lies in, we start at the root and test which side of the partition plane contains <span class="math inline">\(q\)</span>.</p></li>
<li><p>Nearest neighbor search – To find the point in <span class="math inline">\(S\)</span> closest to a query point <span class="math inline">\(q\)</span>, we perform point location to find the cell <span class="math inline">\(c\)</span> containing <span class="math inline">\(q\)</span></p></li>
<li><p>Range search – Which points lie within a query box or region? Starting from the root, check whether the query region intersects (or contains) the cell defining the current node. If it does, check the children; if not, none of the leaf cells below this node can possibly be of interest.</p></li>
<li><p>Partial key search – Suppose we want to find a point p in S, but we do not have full information about p. Say we are looking for someone of age 35 and height 5’8" but of unknown weight in a 3D-tree with dimensions of age, weight, and height. Starting from the root, we can identify the correct descendant for all but the weight dimension</p></li>
</ul>
<p>Kd-trees are most useful for a small to moderate number of dimensions, say from 2 up to maybe 20 dimensions. Algorithms that quickly produce a point provably close to the query point are a recent development in higher-dimensional nearest neighbor search. A sparse weighted graph structure is built from the data set, and the nearest neighbor is found by starting at a random point and walking greedily in the graph towards the query point.</p>
<h2 id="self-balancing-trees">Self-balancing Trees</h2>
<p>Balanced search trees use local <strong>rotation operations</strong> to restructure search trees, moving more distant nodes closer to the root while maintaining the in-order search structure of the tree. The <strong>balance factor</strong> of a node in a binary tree is the height of its right subtree minus the height of its left subtree.</p>
<p>Among balanced search trees, AVL and 2/3 trees are now considered out-dated while red-black trees seem to be more popular. A particularly interesting self-organizing data structure is the splay tree, which uses rotations to move any accessed key to the root. Frequently used or recently accessed nodes thus sit near the top of the tree, allowing faster searches.</p>
<h3 id="avl-trees">AVL Trees</h3>
<p>An AVL tree is a self-balancing binary search tree. A node satisfies the <strong>AVL invariant</strong> if its balance factor is between -1 and 1. A binary tree is AVL-balanced if all of its nodes satisfy the AVL invariant, so we can say that an AVL tree is a binary search tree that is AVL-balanced.</p>
<p>To maintain the AVL condition, perform an insertion/deletion using the typical BST algorithm, then if any nodes have the balance factor invariant violated, restore the invariant. We can simply do so after the recursive Insert, Delete, ExtractMax, or ExtractMin call. So we go down the tree to search for the correct spot to insert the node, and then go back up the tree to restore the AVL invariant. In fact, these restrictions make it straightforward to define a small set of simple, constant-time procedures to restructure the tree to restore the balance factor in these cases. Recall, these procedures are called rotations.</p>
<p>The worst-case running time of AVL tree insertion and deletion is <span class="math inline">\(\mathcal{O}(h)\)</span>, where <span class="math inline">\(h\)</span> is the height of the tree, the same as for the naive insertion and deletion algorithms. An AVL tree with <span class="math inline">\(n\)</span> nodes has height at most <span class="math inline">\(1.44 \log n\)</span>. AVL tree insertion, deletion, and search have worst-case running time <span class="math inline">\(\Theta(\log n)\)</span>, where <span class="math inline">\(n\)</span> is the number of nodes in the tree</p>
<h3 id="redblack-trees">Red–black Trees</h3>
<p>A red–black tree is a kind of self-balancing binary search tree. Each node of the binary tree has an extra bit which is often interpreted as the color (red or black) of the node. These color bits are used to ensure the tree remains approximately balanced during insertions and deletions.</p>
<p>Balance is preserved by painting each node of the tree with one of two colors in a way that satisfies certain properties, which collectively constrain how unbalanced the tree can become in the worst case. When the tree is modified, the new tree is subsequently rearranged and repainted to restore the coloring properties. The properties are designed in such a way that this rearranging and recoloring can be performed efficiently. The balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in <span class="math inline">\(O(\log n)\)</span> time.</p>
<p>Properties:</p>
<ol type="1">
<li><p>Each node is either red or black.</p></li>
<li><p>The root is black. This rule is sometimes omitted. Since the root can always be changed from red to black, but not necessarily vice versa, this rule has little effect on analysis.</p></li>
<li><p>All leaves (NIL) are black.</p></li>
<li><p>If a node is red, then both its children are black.</p></li>
<li><p>Every path from a given node to any of its descendant NIL nodes goes through the same number of black nodes.</p></li>
</ol>
<h3 id="b-trees">B-Trees</h3>
<p>A B-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time (<span class="math inline">\(\mathcal{O}(\log n)\)</span>). The B-tree generalizes the binary search tree, allowing for nodes with more than two children and multiple keys. It is commonly used in databases and file systems.</p>
<p>The idea behind a B-tree is to collapse several levels of a binary search tree into a single large node, so that we can make the equivalent of several search steps before another disk access is needed. With B-trees we can access enormous numbers of keys using only a few disk accesses. To get the full benefit from using a B-tree, it is important to understand how the secondary storage device and virtual memory interact, through constants such as page size and virtual/real address space. Cache-oblivious algorithms can mitigate such concerns.</p>
<p>A B-tree of order <span class="math inline">\(m\)</span> is a tree which satisfies the following properties:</p>
<ol type="1">
<li><p>The root has at least two children if it is not a leaf node.</p></li>
<li><p>Every non-leaf node (except the root) has at least <span class="math inline">\(\lceil \frac{m}{2} \rceil\)</span> child nodes.</p></li>
<li><p>All leaves appear in the same level and carry no information.</p></li>
<li><p>Every node has at most <span class="math inline">\(m\)</span> children.</p></li>
<li><p>A non-leaf node with <span class="math inline">\(k\)</span> children contains <span class="math inline">\(k-1\)</span> keys.</p></li>
</ol>
<p>B-trees are constructed in a bottom-up way: values are inserted into a node based on binary search. If the node reaches its capacity based on the degree of the B-tree, then it is split in half with left or right bias and an appropriate root (median value) and children are selected and appointed to existing or new nodes.</p>
<p>For implementing multi-level indexing in a database, every node will have a key to be indexed by, a pointer to its child nodes in their memory blocks as well as a pointer to a record on the database (value).</p>
<p>In a <strong>B+ tree</strong>, only leaf nodes contain a record pointer with leaf nodes also containing a copy of corresponding parent keys.</p>
<h2 id="graphs">Graphs</h2>
<p>A graph is simply a collection of nodes, some of which may have edges between them. With this definition, we see that a tree is a connected graph that does not have cycles. Graphs can be either <strong>directed</strong> or <strong>undirected</strong>. A graph might consist of multiple isolated subgraphs. If there is a path between every pair of vertices, it is called a <strong>connected</strong> graph. A graph can also have cycles (or not), an <strong>acyclic</strong> graph is one without cycles.</p>
<p>There are two common ways to represent a graph: adjacency lists and adjacency matrices.</p>
<p>In an <strong>adjacency list</strong> representation, every vertex (or node) stores a list of adjacent vertices. In an undirected graph, an edge like (a, b) would be stored twice: once in a’s adjacent vertices and once in b’s adjacent vertices. An adjacency list is faster and uses less space for sparse graphs and conversely, it will be slower for dense graphs.</p>
<p>An <strong>adjacency matrix</strong> is an <span class="math inline">\(N\)</span>x<span class="math inline">\(N\)</span> boolean matrix (where <span class="math inline">\(N\)</span> is the number of nodes), where a true value at <span class="math inline">\(M_{i,j}\)</span> indicates an edge from node <span class="math inline">\(i\)</span> to node <span class="math inline">\(j\)</span>. (You can also use an integer matrix with <span class="math inline">\(O\)</span>s and <span class="math inline">\(1\)</span>s.) In an undirected graph, an adjacency matrix will be symmetric. In a directed graph, it will not (necessarily) be. An adjacency matrix will be faster for dense graphs and simpler for graphs with weighted edges, but it will use more space, always having <span class="math inline">\(\mathcal{O}(V^2)\)</span> space complexity.</p>
<ol type="1">
<li><p>How big will your graph be? – Adjacency matrices make sense only for small or very dense graphs.</p></li>
<li><p>How dense will your graph be? —- If your graph is very dense, meaning that a large fraction of the vertex pairs define edges, there is probably no compelling reason to use adjacency lists. You will be doomed to using <span class="math inline">\(\Theta(n^2)\)</span> space anyway. Indeed, for complete graphs, matrices will be more concise due to the elimination of pointers.</p></li>
<li><p>Which algorithms will you be implementing? – Certain algorithms are more natural on adjacency matrices (such as all-pairs shortest path) and others favor adjacency lists (such as most DFS-based algorithms). Adjacency matrices win for algorithms that repeatedly ask, "Is (i,j) in G?" However, most graph algorithms can be designed to eliminate such queries.</p></li>
<li><p>Will you be modifying the graph over the course of your application? – Efficient static graph implementations can be used when no edge insertion/deletion operations will done following initial construction. Indeed, more common than modifying the topology of the graph is modifying the attributes of a vertex or edge of the graph, such as size, weight, label, or color. Attributes are best handled as extra fields in the vertex or edge records of adjacency lists.</p></li>
</ol>
<p><strong>Planar graphs</strong> are those that can be drawn in the plane so no two edges cross. Planar graphs are always sparse, since any n-vertex planar graph can have at most <span class="math inline">\(3n - 6\)</span> edges, thus they should be represented using adjacency lists. Euler’s Formula states <span class="math inline">\(v-e+f=2\)</span>, where numbers <span class="math inline">\(v =\)</span> verticies <span class="math inline">\(e =\)</span> edges, and <span class="math inline">\(f =\)</span> faces.</p>
<p><strong>Hypergraphs</strong> are generalized graphs where each edge may link subsets of more than two vertices. In contrast, in an ordinary graph, an edge connects exactly two vertices. Two basic data structures for hypergraphs are: incidence matrices, which are analogous to adjacency matrices, and bipartite incidence structures, which are analogous to adjacency lists</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb10" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true"></a><span class="co"># Directed graph </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true"></a><span class="kw">class</span> Graph(<span class="bu">object</span>):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true"></a>        <span class="va">self</span>.nodes <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true"></a>        <span class="va">self</span>.edges <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true"></a>        <span class="va">self</span>.distances <span class="op">=</span> {}</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true"></a>    <span class="kw">def</span> add_node(<span class="va">self</span>, value):</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true"></a>        <span class="va">self</span>.nodes.add(value)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true"></a>    <span class="kw">def</span> add_edge(<span class="va">self</span>, from_node, to_node, distance):</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true"></a>        <span class="va">self</span>.edges[from_node].append(to_node)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true"></a>        <span class="va">self</span>.edges[to_node].append(from_node)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true"></a>        <span class="va">self</span>.distances[(from_node, to_node)] <span class="op">=</span> distance</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true"></a><span class="co"># Undirected graph using Adjacency Matrix</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true"></a><span class="kw">class</span> Vertex:</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true"></a>        <span class="va">self</span>.name <span class="op">=</span> n</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true"></a><span class="kw">class</span> Graph:</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true"></a>    vertices <span class="op">=</span> {}</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true"></a>    edges <span class="op">=</span> []</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true"></a>    edge_indices <span class="op">=</span> {}</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true"></a>    <span class="kw">def</span> add_vertex(<span class="va">self</span>, vertex):</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(vertex, Vertex) <span class="kw">and</span> vertex.name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.vertices:</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true"></a>            <span class="va">self</span>.vertices[vertex.name] <span class="op">=</span> vertex</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true"></a>            <span class="cf">for</span> row <span class="kw">in</span> <span class="va">self</span>.edges:</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true"></a>                row.append(<span class="dv">0</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true"></a>            <span class="va">self</span>.edges.append([<span class="dv">0</span>] <span class="op">*</span> (<span class="bu">len</span>(<span class="va">self</span>.edges)<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true"></a>            <span class="va">self</span>.edge_indices[vertex.name] <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.edge_indices)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true"></a>    <span class="kw">def</span> add_edge(<span class="va">self</span>, u, v, weight<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true"></a>        <span class="cf">if</span> u <span class="kw">in</span> <span class="va">self</span>.vertices <span class="kw">and</span> v <span class="kw">in</span> <span class="va">self</span>.vertices:</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true"></a>            <span class="va">self</span>.edges[<span class="va">self</span>.edge_indices[u]][<span class="va">self</span>.edge_indices[v]] <span class="op">=</span> weight</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true"></a>            <span class="va">self</span>.edges[<span class="va">self</span>.edge_indices[v]][<span class="va">self</span>.edge_indices[u]] <span class="op">=</span> weight</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true"></a>    <span class="kw">def</span> print_graph(<span class="va">self</span>):</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true"></a>        <span class="cf">for</span> v, i <span class="kw">in</span> <span class="bu">sorted</span>(<span class="va">self</span>.edge_indices.items()):</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true"></a>            <span class="bu">print</span>(v <span class="op">+</span> <span class="st">&#39; &#39;</span>, end<span class="op">=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.edges)):</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true"></a>                <span class="bu">print</span>(<span class="va">self</span>.edges[i][j], end<span class="op">=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true"></a>            <span class="bu">print</span>(<span class="st">&#39; &#39;</span>)</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true"></a></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true"></a><span class="co"># Undirected graph using Adjacency Lists</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true"></a><span class="kw">class</span> Vertex:</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n):</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true"></a>        <span class="va">self</span>.name <span class="op">=</span> n</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true"></a>        <span class="va">self</span>.neighbors <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true"></a></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true"></a>    <span class="kw">def</span> add_neighbor(<span class="va">self</span>, v):</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true"></a>        <span class="cf">if</span> v <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.neighbors:</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true"></a>            <span class="va">self</span>.neighbors.append(v)</span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true"></a>            <span class="va">self</span>.neighbors.sort()</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true"></a></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true"></a><span class="kw">class</span> Graph:</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true"></a>    vertices <span class="op">=</span> {}</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true"></a></span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true"></a>    <span class="kw">def</span> add_vertex(<span class="va">self</span>, vertex):</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(vertex, Vertex) <span class="kw">and</span> vertex.name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.vertices:</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true"></a>            <span class="va">self</span>.vertices[vertex.name] <span class="op">=</span> vertex</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true"></a></span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true"></a>    <span class="kw">def</span> add_edge(<span class="va">self</span>, u, v):</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true"></a>        <span class="cf">if</span> u <span class="kw">in</span> <span class="va">self</span>.vertices <span class="kw">and</span> v <span class="kw">in</span> <span class="va">self</span>.vertices:</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true"></a>            <span class="va">self</span>.vertices[u].add_neighbor(v)</span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true"></a>            <span class="va">self</span>.vertices[v].add_neighbor(u)</span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true"></a></span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true"></a>    <span class="kw">def</span> print_graph(<span class="va">self</span>):</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true"></a>        <span class="cf">for</span> key <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="va">self</span>.vertices.keys())):</span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true"></a>            <span class="bu">print</span>(key <span class="op">+</span> <span class="bu">str</span>(<span class="va">self</span>.vertices[key].neighbors))</span></code></pre></div>
<h1 id="algorithms-and-techniques">Algorithms and Techniques</h1>
<h2 id="sequence-search-and-sort">Sequence Search and Sort</h2>
<h3 id="binary-search">Binary Search</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(\log n)\)</span> average and worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>In binary search, we look for an element <span class="math inline">\(x\)</span> in a sorted array by first comparing <span class="math inline">\(x\)</span> to the midpoint of the array. If <span class="math inline">\(x\)</span> is less than the midpoint, then we search the left half of the array. If <span class="math inline">\(x\)</span> is greater than the midpoint, then we search the right half of the array. We then repeat this process, treating the left and right halves as subarrays. Again, we compare <span class="math inline">\(x\)</span> to the midpoint of this subarray and then search either its left or right side. We repeat this process until we either find <span class="math inline">\(x\)</span> or the subarray has size 0.</p>
<p>In general, if we can discover some kind of monotonicity, for example, i.e. if condition(k) is True then condition(k + 1) is also True, then we can consider binary search.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb11" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a><span class="kw">def</span> binary_search(nums, target):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a>    <span class="cf">if</span> <span class="bu">len</span>(nums) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true"></a>        <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true"></a>    left, right <span class="op">=</span> <span class="dv">0</span>, <span class="bu">len</span>(nums) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true"></a>    <span class="cf">while</span> left <span class="op">&lt;=</span> right:</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true"></a>        mid <span class="op">=</span> (left <span class="op">+</span> right) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true"></a>        <span class="cf">if</span> nums[mid] <span class="op">==</span> target:</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true"></a>            <span class="cf">return</span> mid</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true"></a>        <span class="cf">elif</span> nums[mid] <span class="op">&lt;</span> target:</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true"></a>            left <span class="op">=</span> mid <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true"></a>            right <span class="op">=</span> mid <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true"></a><span class="co"># Bisect module    </span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true"></a><span class="im">import</span> bisect</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true"></a>A <span class="op">=</span> [<span class="op">-</span><span class="dv">14</span>, <span class="op">-</span><span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">108</span>, <span class="dv">108</span>, <span class="dv">243</span>, <span class="dv">285</span>, <span class="dv">285</span>, <span class="dv">285</span>, <span class="dv">401</span>]</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true"></a><span class="co">## return index to left or right of first found element in O(logn)</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true"></a>bisect.bisect_left(A, <span class="op">-</span><span class="dv">10</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true"></a>bisect.bisect_right(A, <span class="op">-</span><span class="dv">10</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true"></a><span class="co">## insert into sorted array while maintaining order in O(logn)</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true"></a>bisect.insort(A, <span class="dv">20</span>)</span></code></pre></div>
<h3 id="bubble-sort">Bubble Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n^2)\)</span> average and worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>In bubble sort, we start at the beginning of the array and swap the first two elements if the first is greater than the second. Then, we go to the next pair, and so on, continuously making sweeps of the array until it is sorted. In doing so, the smaller items slowly "bubble" up to the beginning of the list.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb12" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true"></a><span class="kw">def</span> bubble_sort(A):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(A) <span class="op">-</span> <span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true"></a>            <span class="cf">if</span> A[j] <span class="op">&gt;</span> A[j <span class="op">+</span> <span class="dv">1</span>]:</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true"></a>                A[j], A[j <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> A[j <span class="op">+</span> <span class="dv">1</span>], A[j]</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true"></a>    <span class="cf">return</span> A</span></code></pre></div>
<h3 id="selection-sort">Selection Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n^2)\)</span> average and worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>Selection sort is the child’s algorithm: simple, but inefficient. Find the smallest element using a linear scan and move it to the front (swapping it with the front element). Then, find the second smallest and move it, again doing a linear scan. Continue doing this until all the elements are in place.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb13" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true"></a><span class="kw">def</span> selection_sort(A):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(A)):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true"></a>        min_index <span class="op">=</span> i</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i <span class="op">+</span> <span class="dv">1</span>, <span class="bu">len</span>(A)):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true"></a>            <span class="cf">if</span> A[j] <span class="op">&lt;</span> A[min_index]:</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true"></a>                min_index <span class="op">=</span> j</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true"></a>        <span class="cf">if</span> i <span class="op">==</span> min_index:</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true"></a>            <span class="cf">continue</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true"></a>        A[i], A[min_index] <span class="op">=</span> A[min_index], A[i]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true"></a>    <span class="cf">return</span> A</span></code></pre></div>
<h3 id="insertion-sort">Insertion Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n^2)\)</span> average and worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>Given an array <span class="math inline">\(A\)</span> of size <span class="math inline">\(n\)</span>, iterate <span class="math inline">\(i\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span> and insert <span class="math inline">\(A[i]\)</span> into a sorted sub array <span class="math inline">\(A[0, i-1]\)</span> until the entire array is sorted. Sorting occurs through pairwise swaps of elements down to their correct positions.</p>
<p>Insertion sort can be useful when streaming real-time data in large chunks and building real-time visualization for these data sources.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb14" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true"></a><span class="kw">def</span> insertion_sort(A):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(A)):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true"></a>        n <span class="op">=</span> A[i]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true"></a>        pos <span class="op">=</span> i</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true"></a>        <span class="cf">while</span> pos <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> A[pos<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> n:</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true"></a>            A[pos] <span class="op">=</span> A[pos<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true"></a>            pos <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true"></a>        A[pos] <span class="op">=</span> n</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true"></a>    <span class="cf">return</span> A</span></code></pre></div>
<h3 id="merge-sort">Merge Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}( n \log n )\)</span> average and worst case. Space Complexity: Varies on implementation.</p>
<p>Merge sort divides the array in half, sorts each of those halves, and then merges them back together. Each of those halves has the same sorting algorithm applied to it. Eventually, you are merging just two single element arrays. It is the "merge" part that does all the heavy lifting.</p>
<p>The merge method operates by copying all the elements from the target array segment into a helper array, keeping track of where the start of the left and right halves should be. We then iterate through the helper, copying the smaller element from each half into the array. At the end, we copy any remaining elements into the target array.</p>
<p>Merge sort can work well with divide-and-conquer approaches if it comes to large amounts of data stored on different nodes.</p>
<p><span class="math display">\[\begin{aligned}
        T(n) &amp;= 
            \underbrace{c_1}_\text{divide}
            + \underbrace{2T(n/2)}_\text{recursion}
            + \underbrace{c  n}_\text{merge}\\
        &amp;= (1 + \log n) \cdot cn\\
        &amp;= \mathcal{O}(n \log n)
    \end{aligned}\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb15" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true"></a><span class="kw">def</span> _merge_lists(left_sublist, right_sublist):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true"></a>    i, j <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true"></a>    result <span class="op">=</span> []</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> <span class="bu">len</span>(left_sublist) <span class="kw">and</span> j <span class="op">&lt;</span> <span class="bu">len</span>(right_sublist):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true"></a>        <span class="cf">if</span> left_sublist[i] <span class="op">&lt;=</span> right_sublist[j]:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true"></a>            result.append(left_sublist[i])</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true"></a>            result.append(right_sublist[j])</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true"></a>            j <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true"></a>    result <span class="op">+=</span> left_sublist[i:]</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true"></a>    result <span class="op">+=</span> right_sublist[j:]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true"></a>    <span class="cf">return</span> result</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true"></a><span class="kw">def</span> merge_sort(A):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true"></a>    <span class="cf">if</span> <span class="bu">len</span>(A) <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true"></a>        <span class="cf">return</span> A</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true"></a>    <span class="cf">else</span>:</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true"></a>        midpoint <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(A)<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true"></a>        left_sublist <span class="op">=</span> merge_sort(A[:midpoint])</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true"></a>        right_sublist <span class="op">=</span> merge_sort(A[midpoint:])</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true"></a>        <span class="cf">return</span> _merge_lists(left_sublist, right_sublist)</span></code></pre></div>
<h3 id="quick-sort">Quick Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n \log n)\)</span> average, <span class="math inline">\(\mathcal{O}(n^2)\)</span> worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(\log n )\)</span></p>
<p>In quick sort, we pick an element and partition the array, such that all numbers that are less than the partitioning element come before all elements that are greater than it. The partitioning can be performed efficiently through a series of swaps.</p>
<p>If we repeatedly partition the array (and its sub-arrays) around an element, the array will eventually become sorted. However, as the partitioned element is not guaranteed to be the median (or anywhere near the median), our sorting could be very slow. This is the reason for the 0 (<span class="math inline">\(n^2\)</span>) worst case runtime.</p>
<p>If we allow our algorithm to make random choices, we can turn any input into a “random” input simply by preprocessing it, and then applying the regular quicksort function. To run <strong>randomized quicksort</strong> on an array <span class="math inline">\(A\)</span> with length <span class="math inline">\(n\)</span>, we can define the random variable <span class="math inline">\(T_A\)</span> to be the running time of the algorithm. Now we are considering the probability distribution which the algorithm uses to make its random choices, and not a probability distribution over inputs, <span class="math inline">\(E[T_A] = \Theta(n \log{n})\)</span>.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb16" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true"></a><span class="im">import</span> random</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true"></a><span class="kw">def</span> partition(arr, start, end, pivot_mode):</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true"></a>    <span class="cf">if</span> pivot_mode <span class="op">==</span> <span class="st">&#39;first&#39;</span>:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true"></a>        pivot <span class="op">=</span> arr[start]</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true"></a>    <span class="cf">else</span>:</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true"></a>        pivot_index <span class="op">=</span> random.randrange(start, end)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true"></a>        pivot <span class="op">=</span> arr[pivot_index]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true"></a>        arr[pivot_index], arr[start] <span class="op">=</span> arr[start], arr[pivot_index] <span class="co"># place the pivot at the start</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true"></a>    i <span class="op">=</span> start <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(start <span class="op">+</span> <span class="dv">1</span>, end <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true"></a>        <span class="cf">if</span> arr[j] <span class="op">&lt;</span> pivot:</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true"></a>            arr[i], arr[j] <span class="op">=</span> arr[j], arr[i]</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true"></a>    arr[start], arr[i<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> arr[i<span class="op">-</span><span class="dv">1</span>], arr[start]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true"></a>    <span class="cf">return</span> i<span class="op">-</span><span class="dv">1</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true"></a><span class="kw">def</span> quicksort(arr, start, end, pivot_mode<span class="op">=</span><span class="st">&#39;random&#39;</span>):</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true"></a>    <span class="cf">if</span> start <span class="op">&lt;</span> end:</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true"></a>        split <span class="op">=</span> partition(arr, start, end, pivot_mode)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true"></a>        quicksort(arr, start, split<span class="op">-</span><span class="dv">1</span>, pivot_mode)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true"></a>        quicksort(arr, split<span class="op">+</span><span class="dv">1</span>, end, pivot_mode)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true"></a>    <span class="cf">return</span> arr</span></code></pre></div>
<h3 id="heap-sort">Heap Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n \log n)\)</span> average and worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span></p>
<p>Given a heap, we can extract a sorted list of the elements in the heap simply by repeatedly calling Remove and adding the items to a list. In particular, the Heap Sort algorithm does the following:</p>
<ol type="1">
<li><p>Build a min heap from an unordered array A in <span class="math inline">\(\mathcal{O}(n)\)</span>.</p></li>
<li><p>Find the min element A[0] in <span class="math inline">\(\mathcal{O}(1)\)</span>.</p></li>
<li><p>Swap elements A[n] with A[0] so that the min element is at the end of the array in <span class="math inline">\(\mathcal{O}(1)\)</span>.</p></li>
<li><p>Extract node <span class="math inline">\(n\)</span> from the array and decrement the heap size in <span class="math inline">\(\mathcal{O}(1)\)</span>.</p></li>
<li><p>The new node may violate the min heap principle but the children won’t. This allows us to run heapify in <span class="math inline">\(\mathcal{O}(\log n)\)</span>.</p></li>
</ol>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb17" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true"></a><span class="im">import</span> heapq</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true"></a><span class="kw">def</span> heapsort(A):</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true"></a>    h <span class="op">=</span> []</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true"></a>    <span class="cf">for</span> value <span class="kw">in</span> A:</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true"></a>        heapq.heappush(h, value)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true"></a>    <span class="cf">return</span> [heapq.heappop(h) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(h))]</span></code></pre></div>
<h3 id="counting-sort">Counting Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n + k)\)</span> average and worst case, Space Complexity: <span class="math inline">\(\mathcal{O}(n + k)\)</span> (where <span class="math inline">\(k\)</span> is the range of the non-negative key values.)</p>
<p>Instead of using comparison operations as in previous sorting algorithms, counting sort uses integer sorting and relies on a sorting technique based on keys between a specific range. It works by counting the number of objects having distinct key values (a kind of hashing), then doing some arithmetic to calculate the position of each object in the output sequence.</p>
<p>Its running time is linear in the number of items and the difference between the maximum and minimum key values, so it is only suitable for use in situations where the variation in keys is not significantly greater than the number of items.</p>
<p>Counting sort is a <strong>stable</strong> sorting algorithm, meaning the order in which identical values appear in the sorted result will be the same as in the unsorted array. Because of this property, it is often used as a subroutine in another sorting algorithm, radix sort, that can handle larger keys more efficiently.</p>
<ol type="1">
<li><p>In the auxiliary array, add counts of the number in its corresponding index. Note, the index of the auxiliary array represents the numeric value in the original array. Knowing the count of repeated numeric values will help us discern the contiguous indices needed to store each number.</p></li>
<li><p>Iterate over the auxiliary array, add the number to left of the current number, generating a cumulative sum. This will later give us the starting position of the current number since the counts of the previous numbers will need be allocated in the indices to the left in a sorted array.</p></li>
<li><p>Shift all the elements of the auxiliary array to right with the left-most value being zero. This will give us our finalized zero-indexed mapping of array indices (representing a numeric value) to a value representing the starting index in a sorted array.</p></li>
</ol>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb18" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true"></a><span class="kw">def</span> count_sort(A):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true"></a>    output <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>)]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true"></a>    count <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>)]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true"></a>    ans <span class="op">=</span> [<span class="st">&quot;&quot;</span> <span class="cf">for</span> _ <span class="kw">in</span> A]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> A:</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true"></a>        count[<span class="bu">ord</span>(i)] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true"></a>    <span class="co"># Change count[i] so that count[i] now contains actual</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true"></a>    <span class="co"># position of this character in output array</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>):</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true"></a>        count[i] <span class="op">+=</span> count[i<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true"></a>    <span class="co"># Build the output character array</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(A)):</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true"></a>        output[count[<span class="bu">ord</span>(A[i])]<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> A[i]</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true"></a>        count[<span class="bu">ord</span>(A[i])] <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true"></a>    <span class="co"># Copy the output array to A, so that A now</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true"></a>    <span class="co"># contains sorted characters</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(A)):</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true"></a>        ans[i] <span class="op">=</span> output[i]</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true"></a>    <span class="cf">return</span> ans</span></code></pre></div>
<h3 id="radix-sort">Radix Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(w \cdot n)\)</span> average and worst case, Space Complexity: <span class="math inline">\(\mathcal{O}(w + n)\)</span> (where <span class="math inline">\(w\)</span> is the number of bits required to store each key and <span class="math inline">\(n\)</span> is the length of the array to be sorted)</p>
<p>Radix is a Latin word for "root" which can be considered a synonym for an arithmetical base, where decimal is base 10. For simplicity, say you want to use the decimal radix (= 10) for sorting. Radix sort, sometimes called bucket sort, makes use of the stable sorting property by iteratively applying counting sort on a single digit of all the elements, i.e. by sorting the numbers by tens and then putting them together again; then by hundreds and so on, which will eventually produce an array sorted in ascending order.</p>
<p>Radix sort, can be applied to data that can be sorted lexicographically, i.e integers, words, playing cards, etc. Unlike radix sort, quicksort is universal, while radix sort is only useful for fixed length integer keys. <span class="math inline">\(w\)</span> can be interpreted as the length of the longest value in an array of length <span class="math inline">\(n\)</span>. If <span class="math inline">\(k = n\)</span>, then <span class="math inline">\(\mathcal{O}(k * n) = \mathcal{O}(n^2)\)</span>. We see that radix sort will only outperform quicksort when the longest value can be interpreted in less values (digits) than the size of the given array.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb19" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true"></a><span class="kw">def</span> radix_sort(A):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true"></a>    RADIX <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true"></a>    maxLength <span class="op">=</span> <span class="va">False</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true"></a>    tmp, digit <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true"></a>    <span class="cf">while</span> <span class="kw">not</span> maxLength:</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true"></a>        maxLength <span class="op">=</span> <span class="va">True</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true"></a>        <span class="co"># declare and initialize buckets</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true"></a>        buckets <span class="op">=</span> [<span class="bu">list</span>() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(RADIX)]</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true"></a>        <span class="co"># split A into buckets</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true"></a>        <span class="cf">for</span> num <span class="kw">in</span> A:</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true"></a>            tmp <span class="op">=</span> num <span class="op">/</span> digit</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true"></a>            buckets[tmp <span class="op">%</span> RADIX].append(num)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true"></a>            <span class="cf">if</span> maxLength <span class="kw">and</span> tmp <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true"></a>                maxLength <span class="op">=</span> <span class="va">False</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true"></a>        <span class="co"># empty buckets into array A</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true"></a>        i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(RADIX):</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true"></a>            bucket <span class="op">=</span> buckets[j]</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true"></a>            <span class="cf">for</span> num <span class="kw">in</span> bucket:</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true"></a>                A[i] <span class="op">=</span> num</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true"></a>                i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true"></a>        <span class="co"># move to next digit</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true"></a>        digit <span class="op">*=</span> RADIX</span></code></pre></div>
<h3 id="timsort">Timsort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span> best-case, <span class="math inline">\(\mathcal{O}(n\log n)\)</span> average and worst case, Memory <span class="math inline">\(\mathcal{O}(n)\)</span>.</p>
<p>Timsort is a hybrid stable sorting algorithm, derived from merge sort and insertion sort, designed to perform well on many kinds of real-world data. The algorithm finds subsequences of the data that are already ordered (runs) and uses them to sort the remainder more efficiently. This is done by merging runs until certain criteria are fulfilled. Timsort has been Python’s standard sorting algorithm since version 2.3.</p>
<h2 id="array-analysis-methods">Array Analysis Methods</h2>
<h3 id="two-pointer-technique">Two Pointer Technique</h3>
<p>Time complexity: <span class="math inline">\(\mathcal{O}(n^2)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>The two pointer technique uses two references to values in a given array to check if they satisfy a condition, otherwise the pointers usually move towards the middle of the array being iterated over.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb20" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true"></a><span class="kw">def</span> left_right_boundary(<span class="va">self</span>, seq):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true"></a>    left, right <span class="op">=</span> <span class="dv">0</span>, <span class="bu">len</span>(seq) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true"></a>    <span class="cf">while</span> left <span class="op">&lt;</span> right:</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true"></a>        <span class="cf">if</span> <span class="va">self</span>.left_condition(left):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true"></a>            left <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true"></a>        <span class="cf">if</span> <span class="va">self</span>.right_condition(right):</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true"></a>            right <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true"></a>        <span class="va">self</span>.validate(left, right)</span></code></pre></div>
<h3 id="fast-and-slow-pointers">Fast and Slow Pointers</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>The fast and slow pointers/runners technique (a.k.a. Floyd’s Tortoise and Hare Algorithm) is useful when dealing with cyclic linked lists or arrays. By moving at different rates, the algorithm proves that the two pointers are either going to meet eventually or one will reach the end of the list. That is, the fast pointer should catch the slow pointer once both the pointers are in a cyclic loop.</p>
<p>If the list has <span class="math inline">\(n\)</span> nodes, then in <span class="math inline">\(\leq n\)</span> steps, either the fast pointer will find the end of the list, or there is a loop and the slow pointer will be in the loop. Suppose the loop is of length <span class="math inline">\(m \leq n\)</span>, then once the slow pointer is in the loop, both the fast and slow pointers will be stuck in the loop forever. Each step, the distance between the fast and the slow pointers will increase by 1. When the distance is divisible by <span class="math inline">\(m\)</span>, then the fast and slow pointers will be on the same node and the algorithm terminates. The distance will reach a number divisible by <span class="math inline">\(m\)</span> in <span class="math inline">\(\leq m\)</span> steps.</p>
<p>So, getting the slow pointer to the loop, and then getting the fast and slow pointers to meet takes <span class="math inline">\(\leq n + m \leq 2n\)</span> steps, and that is in <span class="math inline">\(\mathcal{O}(n)\)</span>.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb21" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true"></a><span class="kw">def</span> has_cycle(<span class="va">self</span>, head):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true"></a>    <span class="cf">try</span>:</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true"></a>        slow, fast <span class="op">=</span> head, head.<span class="bu">next</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true"></a>        <span class="cf">while</span> slow <span class="kw">is</span> <span class="kw">not</span> fast:</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true"></a>            slow <span class="op">=</span> slow.<span class="bu">next</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true"></a>            fast <span class="op">=</span> fast.<span class="bu">next</span>.<span class="bu">next</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true"></a>    <span class="cf">except</span> <span class="pp">AttributeError</span>:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true"></a>        <span class="cf">return</span> <span class="va">False</span></span></code></pre></div>
<h3 id="sliding-window-technique">Sliding Window Technique</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(k)\)</span>, where <span class="math inline">\(k\)</span> is the length of a pattern or restrict sequence</p>
<p>Sliding windows are commonly used to find a match or maximum/minimum in a given subarray or substring. It uses two pointers as the boundary of a sliding window to traverse and can also use a counter dictionary to maintain current state.</p>
<ol type="1">
<li><p>Define two pointers, start and end, to represent the sliding window.</p></li>
<li><p>Move end to search for a valid window.</p></li>
<li><p>When a valid window is found, move start to find a smaller valid window, continuing until the smallest valid window is found.</p></li>
</ol>
<p>A possible variation is to use two sliding windows. This may be necessary when a question asks to find the number of valid sub-sequence of <em>exactly</em> <span class="math inline">\(K\)</span> elements.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Then we want to find <span class="math inline">\(exactly(K) = atMost(K) - atMost(K-1)\)</span> and may define two sliding windows, one which counts subsequences with length <span class="math inline">\(&lt;= k\)</span> and another with length <span class="math inline">\(&lt;= k-1\)</span>.</p>
<p>Another challenging variation involves finding the length of a window in which the absolute difference is maximized but under a given limit.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In this case, we maintain two double-ended queues (deque), one of minimums that is kept monotonically increasing and the other of maximums that is kept monotonically decreasing. After appending elements on to the end of both queues while maintaining monotonic order, we then update the front of the deques so that the difference between their first elements does not exceede the given limit, increment a counter if we popleft. This counter corresponds to the left pointer of a sliding window and we want the max valid window.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb22" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true"></a><span class="kw">def</span> basic_sliding_window(<span class="va">self</span>, seq):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true"></a>    start, end <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true"></a>    <span class="cf">while</span> end <span class="op">&lt;</span> <span class="bu">len</span>(seq):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true"></a>        <span class="co"># end grows in the outer loop</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true"></a>        end <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true"></a>        <span class="co"># start grows with some restrict</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true"></a>        <span class="cf">while</span> <span class="va">self</span>.start_condition(start):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true"></a>            <span class="co"># process logic before pointers movement</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true"></a>            <span class="va">self</span>.process_logic1(start, end)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true"></a>            <span class="co"># start grows in the inner loop</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true"></a>            start <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true"></a>        <span class="co"># or process logic after pointers movement</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true"></a>        <span class="va">self</span>.process_logic2(start, end)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true"></a><span class="co"># Using a counter</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true"></a><span class="kw">def</span> sliding_window_with_counter(sequence, max_length):</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true"></a>    ans <span class="op">=</span> start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true"></a>    count <span class="op">=</span> collections.Counter()</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true"></a>    <span class="cf">for</span> end, x <span class="kw">in</span> <span class="bu">enumerate</span>(sequence):</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true"></a>        count[x] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true"></a>        <span class="co"># while invalid condition, reduce counter and shorten window </span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true"></a>        <span class="cf">while</span> <span class="bu">len</span>(count) <span class="op">&gt;=</span> max_length:</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true"></a>            count[sequence[start]] <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true"></a>            <span class="cf">if</span> count[sequence[start]] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true"></a>                <span class="kw">del</span> count[sequence[start]]</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true"></a>            start <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true"></a>        ans <span class="op">=</span> <span class="bu">max</span>(ans, end <span class="op">-</span> start <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true"></a>    <span class="cf">return</span> ans</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true"></a>    </span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true"></a><span class="co"># Using monotonic double-ended queues</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true"></a><span class="kw">def</span> longest_subarray(A, limit):</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true"></a>    maxdq <span class="op">=</span> collections.deque()</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true"></a>    mindq <span class="op">=</span> collections.deque()</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true"></a>    i <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true"></a>    <span class="cf">for</span> a <span class="kw">in</span> A:</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true"></a>        <span class="cf">while</span> <span class="bu">len</span>(maxdq) <span class="kw">and</span> a <span class="op">&gt;</span> maxdq[<span class="op">-</span><span class="dv">1</span>]: maxdq.pop()</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true"></a>        <span class="cf">while</span> <span class="bu">len</span>(mindq) <span class="kw">and</span> a <span class="op">&lt;</span> mindq[<span class="op">-</span><span class="dv">1</span>]: mindq.pop()</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true"></a>        maxdq.append(a)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true"></a>        mindq.append(a)</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true"></a>        <span class="cf">if</span> maxdq[<span class="dv">0</span>] <span class="op">-</span> mindq[<span class="dv">0</span>] <span class="op">&gt;</span> limit:</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true"></a>            <span class="cf">if</span> maxdq[<span class="dv">0</span>] <span class="op">==</span> A[i]: maxdq.popleft()</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true"></a>            <span class="cf">if</span> mindq[<span class="dv">0</span>] <span class="op">==</span> A[i]: mindq.popleft()</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">len</span>(A) <span class="op">-</span> i</span></code></pre></div>
<h3 id="single-pass-with-lookup-table">Single-pass with Lookup Table</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span></p>
<p>A lookup table is an example of making a time-space tradeoff. This technique is useful when searching an array for a pair of values, though the method can be extrapolated to triples and more. Given an array and a target we first initialize a lookup table, usually as a hash table or dictionary. Next, we iterate over the array checking if the complement to the current value needed to satisfy the target exists in our lookup table. If it exists, meaning we’ve visited the complement before, we retrieve the value from the pointer in the lookup and return it with the current index. Otherwise we add the compliment with the current index as a key value pair in the lookup table.</p>
<p>The key takeaway is that when finding pairs to meet a condition, we typically require nested for loops to run <span class="math inline">\(\mathcal{O}(\frac{n(n-1)}{2}) = \mathcal{O}(n^2)\)</span> comparisons. By instead storing and searching a hashmap only for the desired pairing, we reduce our operations to <span class="math inline">\(\mathcal{O}(n)\)</span>. When we need to find triples we can reduce 3 for loops and a running time of <span class="math inline">\(\mathcal{O}(n^3)\)</span> to only two loops and running time of <span class="math inline">\(\mathcal{O}(n^2))\)</span>. Similar optimizations hold for larger groups.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb23" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true"></a><span class="kw">def</span> single_pass_lookup(nums, target):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true"></a>    lookup <span class="op">=</span> {}</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true"></a>    <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(nums):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true"></a>        <span class="cf">if</span> target <span class="op">-</span> v <span class="kw">in</span> lookup:</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true"></a>            <span class="cf">return</span> i, lookup[target <span class="op">-</span> v]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true"></a>        lookup[v] <span class="op">=</span> i</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;Target not in list.&#39;</span>)</span></code></pre></div>
<h3 id="range-operations-on-array">Range Operations on Array</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(Q + n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span>, where <span class="math inline">\(Q\)</span> is the number of operations or queries</p>
<p>Given an array <span class="math inline">\(A\)</span> of 0’s of size <span class="math inline">\(n\)</span>, perform <span class="math inline">\(Q\)</span> operations or queries by incrementing values in the subarray <span class="math inline">\(A[L: R]\)</span> by 1. A naive brute force solution of performing all the given operations will result in time complexity of <span class="math inline">\(\mathcal{O}(Q\cdot n)\)</span>.</p>
<p>However, using a numerical method we are able to reduce the time complexity to <span class="math inline">\(\mathcal{O}(Q + n)\)</span>. This technique involves creating a secondary array <span class="math inline">\(B\)</span> and only incrementing the value at the left endpoint, <span class="math inline">\(L\)</span> by 1 and decrementing the value at index <span class="math inline">\(R + 1\)</span> by 1. After repeating this process for all queries, to find the true desired value of <span class="math inline">\(A[i]\)</span> we can find the prefix sum of <span class="math inline">\(B\)</span> from <span class="math inline">\(B[0:i]\)</span>.</p>
<p>If instead we want to find the maximum in the array after performing <span class="math inline">\(Q\)</span> range operations, we can modify the above technique which will give us an algorithm that runs in <span class="math inline">\(\mathcal{O}(n)\)</span>. Again, for each range interval we increment the left pointer by 1 and decrement the right by 1. By the end of all this, we have an array that shows the difference between every successive element. From here, we iterate over the array while maintaining a running sum and keeping track of the maximum of the sum.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb24" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true"></a><span class="kw">def</span> max_after_operations(n, operations):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true"></a>    B <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> (n <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true"></a>    <span class="cf">for</span> start, end, incr <span class="kw">in</span> operations:</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true"></a>        B[start <span class="op">-</span> <span class="dv">1</span>] <span class="op">+=</span> incr</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true"></a>        <span class="cf">if</span> stop <span class="op">&lt;=</span> <span class="bu">len</span>(B):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true"></a>            B[stop] <span class="op">-=</span> incr<span class="op">;</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true"></a>    max_value <span class="op">=</span> cur <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> B:</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true"></a>        cur <span class="op">=</span> cur <span class="op">+</span> i<span class="op">;</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true"></a>        max_value <span class="op">=</span> <span class="bu">max</span>(max_value, cur)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true"></a>    <span class="cf">return</span> max_value</span></code></pre></div>
<h3 id="kadanes-algorithm">Kadane’s Algorithm</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(1)\)</span></p>
<p>The maximum subarray sum problem is the task of finding a contiguous subarray with the largest sum within a given one-dimensional array <span class="math inline">\(A[1...n]\)</span> of numbers.</p>
<p>This problem can be solved using several different techniques, including brute force, divide and conquer, dynamic programming, and reduction to shortest paths. Kadane’s algorithm can be viewed as a trivial example of dynamic programming which will be visited in more detail later.</p>
<ol type="1">
<li><p>Use the input array of nums to store the candidate subarrays sum (i.e. the greatest contiguous sum so far).</p></li>
<li><p>Ignore cumulative negatives, as they don’t contribute positively to the sum.</p></li>
<li><p>Return the max value of the mutated nums array, which will be the maximum contiguous subararry sum.</p></li>
</ol>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb25" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true"></a><span class="kw">def</span> maxSubArray(<span class="va">self</span>, nums: List[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(nums)):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true"></a>        <span class="cf">if</span> nums[i<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true"></a>            nums[i] <span class="op">+=</span> nums[i<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">max</span>(nums)</span></code></pre></div>
<h3 id="prefix-sums-with-binary-search">Prefix Sums with Binary Search</h3>
<p>Similar to Kadane’s algorithm, we can create an alternative representation of a given array of numbers which will speed up finding a solution. For each number in a sequence, its corresponding prefix sum, also known as cumulative sum, is the sum of all previous numbers in the sequence plus the number itself. The trick here, is to relate the original list of numbers to a corresponding list of prefix sums using their index.</p>
<p>If all numbers are positive, then we see that the list of prefix sums would be strictly monotonically increasing. If we are given a list of positive numbers and we want to find which offset or range a new number corresponds to, we can convert the numbers (which represent some kind of weight) to list of relative offsets (i.e. prefix sums). Our task is then to fit the target offset into the list so that the ascending order is maintained using binary search (<span class="math inline">\(\mathcal{O}(\log(n))\)</span>).</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb26" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true"></a><span class="kw">def</span> prefix_sum(<span class="va">self</span>, weights: List[<span class="bu">int</span>], target: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true"></a>    cumulative, prefix_sums <span class="op">=</span> <span class="dv">0</span>, []</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true"></a>    <span class="cf">for</span> w <span class="kw">in</span> weights:</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true"></a>        cumulative <span class="op">+=</span> w</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true"></a>        prefix_sums.append(cumulative)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true"></a>        </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true"></a>    low, high <span class="op">=</span> <span class="dv">0</span>, <span class="bu">len</span>(prefix_sums)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true"></a>    <span class="cf">while</span> low <span class="op">&lt;=</span> high:</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true"></a>        mid <span class="op">=</span> low <span class="op">+</span> (high <span class="op">-</span> low) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true"></a>        <span class="cf">if</span> target <span class="op">&gt;</span> prefix_sums[mid]:</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true"></a>            low <span class="op">=</span> mid <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true"></a>            high <span class="op">=</span> mid <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true"></a>    <span class="cf">return</span> low</span></code></pre></div>
<h3 id="merge-intervals">Merge Intervals</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n \log n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span></p>
<p>An interval problem has an input of a 2d array in which each nested array represents a start and an end value. The interval can also be represented as an object with start and end attributes.</p>
<p>Given two intervals A and B, there will be six different ways the two intervals can relate to each other:</p>
<ol type="1">
<li><p>A and B do not overlap, A before B</p></li>
<li><p>A and B overlap, B ends after A</p></li>
<li><p>A completely overlaps B</p></li>
<li><p>A and B overlap, A ends after B</p></li>
<li><p>A and B do not overlap, B before A</p></li>
</ol>
<p>If a.start <span class="math inline">\(\leq\)</span> b.start, only 1, 2 and 3 are possible from the above scenarios. Our goal is to merge the intervals whenever they overlap.</p>
<p>For unweighted job scheduling, see the greedy programming section. For weighted job scheduling, see dynamic programming.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb27" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true"></a><span class="kw">def</span> merge_intervals(<span class="va">self</span>, intervals):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true"></a>    <span class="cf">if</span> <span class="bu">len</span>(intervals) <span class="op">&lt;</span> <span class="dv">2</span>: <span class="cf">return</span> intervals</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true"></a>    intervals.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">0</span>])</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true"></a>    merged <span class="op">=</span> []</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true"></a>    start <span class="op">=</span> intervals[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true"></a>    end <span class="op">=</span> intervals[<span class="dv">0</span>][<span class="dv">1</span>]</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(intervals)):</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true"></a>        interval <span class="op">=</span> intervals[i]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true"></a>        <span class="cf">if</span> interval[<span class="dv">0</span>] <span class="op">&lt;=</span> end:  <span class="co"># overlapping intervals</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true"></a>            end <span class="op">=</span> <span class="bu">max</span>(interval[<span class="dv">1</span>], end)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true"></a>        <span class="cf">else</span>:  <span class="co"># non-overlapping interval, add the previous interval and reset</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true"></a>            merged.append([start, end])</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true"></a>            start <span class="op">=</span> interval[<span class="dv">0</span>]</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true"></a>            end <span class="op">=</span> interval[<span class="dv">1</span>]</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true"></a>    merged.append([start, end])  <span class="co"># add the last interval</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true"></a>    <span class="cf">return</span> merged</span></code></pre></div>
<h2 id="string-analysis-methods">String Analysis Methods</h2>
<p>A string is a sequence of ASCII characters. Many analysis techniques that apply to arrays can also be used on string inputs when they are interpreted as character arrays.</p>
<h3 id="kmp-pattern-matching">KMP Pattern Matching</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(n)\)</span>, Space Complexity: <span class="math inline">\(\mathcal{O}(k)\)</span>, where <span class="math inline">\(n\)</span> is the length of the string and <span class="math inline">\(k\)</span> is the length of the pattern</p>
<p>KMP (Knuth Morris Pratt) pattern matching improves the worst case complexity of a naive approach to <span class="math inline">\(\mathcal{O}(n)\)</span>. The basic idea behind KMP’s algorithm is that whenever we detect a mismatch after some matches, we already know some of the characters in the text of the next window. Instead of wasting computation on previous matches, we use a pre-computed lookup table to skip to the first instance of a match of the starting character.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb28" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true"></a><span class="kw">class</span> KMP:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true"></a>    <span class="kw">def</span> build_lps(<span class="va">self</span>, pattern):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true"></a>        <span class="co">&quot;&quot;&quot; Helper function for strStr.</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true"></a><span class="co">        Returns longest proper suffix array for string pattern.</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true"></a><span class="co">        Each lps_array[i] is the length of the longest proper prefix</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true"></a><span class="co">        which is equal to suffix for pattern ending at character i.</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true"></a><span class="co">        Proper means that whole string cannot be prefix or suffix.</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true"></a><span class="co">        Time complexity: O(m). Space complexity: O(1), where</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true"></a><span class="co">        m is the length of the pattern, space used for lps array isn&#39;t included.</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true"></a>        m <span class="op">=</span> <span class="bu">len</span>(pattern)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true"></a>        lps_array <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> m</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true"></a>        i, j <span class="op">=</span> <span class="dv">1</span>, <span class="dv">0</span>  <span class="co"># start from the 2nd character in pattern</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true"></a>        <span class="cf">while</span> i <span class="op">&lt;</span> m:</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true"></a>            <span class="cf">if</span> pattern[i] <span class="op">==</span> pattern[j]:</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true"></a>                lps_array[i] <span class="op">=</span> j <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true"></a>                j <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true"></a>                i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true"></a>            <span class="cf">else</span>:</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true"></a>                <span class="cf">if</span> j <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true"></a>                    j <span class="op">=</span> lps_array[j <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true"></a>                <span class="cf">else</span>:</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true"></a>                    lps_array[i] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true"></a>        </span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true"></a>    <span class="kw">def</span> search(<span class="va">self</span>, text, pattern):</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true"></a>        <span class="co">&quot;&quot;&quot; Returns index of 1st occurence of pattern in text.</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true"></a><span class="co">        Returns -1 if pattern is not in the text.</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true"></a><span class="co">        Knuth-Morris-Pratt algorithm.</span></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true"></a><span class="co">        Time complexity: O(n + m). Space complexity: O(m).</span></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true"></a>        <span class="co"># special cases</span></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true"></a>        <span class="cf">if</span> <span class="kw">not</span> text <span class="kw">or</span> <span class="kw">not</span> pattern : <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true"></a>        <span class="co"># build longest proper suffix array for pattern</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true"></a>        lps_array <span class="op">=</span> <span class="va">self</span>.build_lps(pattern)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true"></a>        n, m <span class="op">=</span> <span class="bu">len</span>(text), <span class="bu">len</span>(pattern)</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true"></a>        i, j <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true"></a>        <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true"></a>            <span class="co"># current characters match, move to the next characters</span></span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true"></a>            <span class="cf">if</span> text[i] <span class="op">==</span> pattern[j]:</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true"></a>                i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true"></a>                j <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true"></a>            <span class="co"># current characters don&#39;t match</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true"></a>            <span class="cf">else</span>:</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true"></a>                <span class="cf">if</span> j <span class="op">&gt;</span> <span class="dv">0</span>:  <span class="co"># try start with previous longest prefix</span></span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true"></a>                    j <span class="op">=</span> lps_array[j <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true"></a>                <span class="co"># 1st character of pattern doesn&#39;t match character in text</span></span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true"></a>                <span class="co"># go to the next character in text</span></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true"></a>                <span class="cf">else</span>:</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true"></a>            <span class="co"># whole pattern matches text, match is found</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true"></a>            <span class="cf">if</span> j <span class="op">==</span> m:</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true"></a>                <span class="cf">return</span> i <span class="op">-</span> m</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true"></a>        <span class="co"># no match was found</span></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true"></a>        <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span></span></code></pre></div>
<h3 id="rabinkarp">Rabin–Karp</h3>
<p>The Rabin–Karp algorithm is a string-searching algorithm that uses hashing to find an exact match of a pattern string in a text. It uses a rolling hash to quickly filter out positions of the text that cannot match the pattern, and then checks for a match at the remaining positions.</p>
<h3 id="edit-distance">Edit Distance</h3>
<p>Edit distance is a way of quantifying how dissimilar two strings are to one another by counting the minimum number of operations required to transform one string into the other.</p>
<p>Different types of edit distance allow different sets of string operations. For instance:</p>
<ol type="1">
<li><p>The <strong>Levenshtein distance</strong> allows deletion, insertion and substitution.</p></li>
<li><p>The <strong>Longest common subsequence (LCS) distance</strong> allows only insertion and deletion, not substitution.</p></li>
<li><p>The <strong>Hamming distance</strong> allows only substitution, hence, it only applies to strings of the same length.</p></li>
<li><p>The <strong>Damerau–Levenshtein distance</strong> allows insertion, deletion, substitution, and the transposition of two adjacent characters.</p></li>
<li><p>The <strong>Jaro distance</strong> allows only transposition.</p></li>
</ol>
<h2 id="heap-use-cases">Heap Use Cases</h2>
<h3 id="top-k-numbers">Top K Numbers</h3>
<p>The best data structure to keep track of top <span class="math inline">\(K\)</span> elements is a heap. If we iterate through an array, one element at a time, and keep <span class="math inline">\(K\)</span>-th largest element in a heap such that each time we find a larger number than the smallest number in the heap, we do two things:</p>
<ol type="1">
<li><p>Take out the smallest number from the heap</p></li>
<li><p>Insert the larger number into the heap</p></li>
</ol>
<p>This will ensure that we always have top <span class="math inline">\(K\)</span> largest numbers in the heap. To easily remove the smallest value we may use a min-heap.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb29" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true"></a><span class="im">import</span> heapq</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true"></a><span class="co"># For maintaining a class</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true"></a><span class="kw">class</span> KthLargest:</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, k: <span class="bu">int</span>, nums):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true"></a>        <span class="va">self</span>.pq, <span class="va">self</span>.k <span class="op">=</span> [], k</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true"></a>        <span class="cf">for</span> n <span class="kw">in</span> nums:</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true"></a>            <span class="va">self</span>.add(n)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true"></a>    <span class="kw">def</span> add(<span class="va">self</span>, val: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true"></a>        heapq.heappush(<span class="va">self</span>.pq, val)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.pq) <span class="op">&gt;</span> <span class="va">self</span>.k:</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true"></a>            heapq.heappop(<span class="va">self</span>.pq)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true"></a>        <span class="cf">return</span> <span class="va">self</span>.pq[<span class="dv">0</span>]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true"></a><span class="co"># For one-time calculation</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true"></a><span class="kw">def</span> findKthLargest(<span class="va">self</span>, nums: List[<span class="bu">int</span>], k: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true"></a>        min_heap <span class="op">=</span> []</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true"></a>            heapq.heappush(min_heap, nums[i])</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k, <span class="bu">len</span>(nums)):</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true"></a>            <span class="cf">if</span> nums[i] <span class="op">&gt;</span> min_heap[<span class="dv">0</span>]:</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true"></a>                heapq.heappop(min_heap)</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true"></a>                heapq.heappush(min_heap, nums[i])</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true"></a>        <span class="cf">return</span> min_heap[<span class="dv">0</span>]</span></code></pre></div>
<h3 id="two-heaps-median-of-data-stream">Two Heaps (Median of Data Stream)</h3>
<p>If we maintain two heaps, we can keep track of the bigger half and the smaller half of a stream of data. The bigger half is kept in a min heap, such that the smallest element in the bigger half is at the root. The smaller half is kept in a max heap, such that the biggest element of the smaller half is at the root. Now, with these data structures, we have the potential median elements at the roots. If the heaps are no longer the same size, we can easily re-balance the heaps by popping an element off the one heap and pushing it onto the other.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb30" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true"></a><span class="im">from</span> heapq <span class="im">import</span> <span class="op">*</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true"></a><span class="kw">class</span> MedianFinder:</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true"></a>        <span class="va">self</span>.heaps <span class="op">=</span> [], []</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true"></a>    <span class="kw">def</span> addNum(<span class="va">self</span>, num):</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true"></a>        small, large <span class="op">=</span> <span class="va">self</span>.heaps</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true"></a>        <span class="co">#convert a min heap to a max heap. heapq only has a min heap by default.</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true"></a>        heappush(small, <span class="op">-</span>heappushpop(large, num))</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(large) <span class="op">&lt;</span> <span class="bu">len</span>(small):</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true"></a>            heappush(large, <span class="op">-</span>heappop(small))</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true"></a>    <span class="kw">def</span> findMedian(<span class="va">self</span>):</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true"></a>        small, large <span class="op">=</span> <span class="va">self</span>.heaps</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(large) <span class="op">&gt;</span> <span class="bu">len</span>(small):</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true"></a>            <span class="cf">return</span> <span class="bu">float</span>(large[<span class="dv">0</span>])</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true"></a>        <span class="cf">return</span> (large[<span class="dv">0</span>] <span class="op">-</span> small[<span class="dv">0</span>]) <span class="op">/</span> <span class="fl">2.0</span></span></code></pre></div>
<h2 id="tree-traversal">Tree Traversal</h2>
<p>Given a binary tree, an <strong>in-order traversal</strong> (LNR) means to visit the left branch, then the current node, and finally, the right branch. A <strong>pre-order traversal</strong> (NLR) visits the current node before its child nodes, i.e. the root is always the first node visited. A <strong>post-order traversal</strong> (LRN) visits the current node after its child nodes, i.e. the root node is always the last node visited. A <strong>breadth-first search</strong> of a tree, a.k.a. level order tree traversal, iteratively visits all the nodes at the same height from left to right.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb31" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true"></a><span class="kw">def</span> inorder(root): </span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true"></a>    <span class="cf">if</span> root: </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true"></a>        inorder(root.left) </span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true"></a>        <span class="bu">print</span>(root.val)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true"></a>        inorder(root.right) </span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true"></a>  </span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true"></a><span class="kw">def</span> postorder(root): </span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true"></a>    <span class="cf">if</span> root: </span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true"></a>        postorder(root.left) </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true"></a>        postorder(root.right) </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true"></a>        <span class="bu">print</span>(root.val)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true"></a>        </span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true"></a><span class="kw">def</span> preorder(root): </span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true"></a>    <span class="cf">if</span> root: </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true"></a>        <span class="bu">print</span>(root.val)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true"></a>        preorder(root.left) </span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true"></a>        preorder(root.right)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true"></a>        </span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true"></a><span class="kw">def</span> levelorder(root):</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true"></a>    q, level <span class="op">=</span> collections.deque(), <span class="dv">0</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true"></a>    q.append(root)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true"></a>    <span class="cf">while</span> q:</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true"></a>        level <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(q)):</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true"></a>            node <span class="op">=</span> q.popleft()</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true"></a>            <span class="bu">print</span>(node.val)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true"></a>            <span class="cf">if</span> node.left:</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true"></a>                q.append(node.left)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true"></a>            <span class="cf">if</span> node.right:</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true"></a>                q.append(node.right)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true"></a>        <span class="co"># perform a level based condition check here</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true"></a>    <span class="cf">return</span></span></code></pre></div>
<h2 id="graph-traversal">Graph Traversal</h2>
<h3 id="breadth-first-search">Breadth-First Search</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|V| + |E|)\)</span> worst case, Space Complexity: <span class="math inline">\(\mathcal{O}(|V|)\)</span></p>
<p>In a breadth-first search (BFS), we start at the root (or another arbitrarily selected node) and explore each neighbor before going on to any of their children. That is, we go wide before we go deep.</p>
<p>In BFS, node x visits each of x’s neighbors before visiting any of their neighbors. You can think of this as searching level by level out from x. An iterative solution involving a <strong>queue</strong> usually works best, this means that you should avoid using recursion which will have a stack LIFO ordering.</p>
<p>In an unweighted graph, since BFS explores all neighbors at the same depth, it can be used to find the shortest path between a start and a target node.</p>
<p>When a graph is implemented with an Adjacency List, the time complexity of BFS will be <span class="math inline">\(\mathcal{O}(|V| + |E|)\)</span>, but when implemented with an Adjacency Matrix it will be <span class="math inline">\(\mathcal{O}(|V|^2)\)</span>. The complexity difference occurs due to the fact that in an Adjacency Matrix we must iterate through all possible adjacent edges to find existing outgoing edges, which takes <span class="math inline">\(O(|V|)\)</span> time summed over <span class="math inline">\(|V|\)</span> vertices. So <span class="math inline">\(\mathcal{O}(|V| + |E|) = \mathcal{O}(|V| + |V|^2) = \mathcal{O}(|V|^2)\)</span>.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb32" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> deque</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true"></a><span class="co"># BFS on graph represented as an adjacency matrix</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true"></a><span class="kw">def</span> bfs(adj_matrix):</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true"></a>    <span class="cf">if</span> <span class="kw">not</span> adj_matrix: <span class="cf">return</span> []</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true"></a>    rows, cols <span class="op">=</span> <span class="bu">len</span>(adj_matrix), <span class="bu">len</span>(adj_matrix[<span class="dv">0</span>])</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true"></a>    directions <span class="op">=</span> ((<span class="dv">0</span>, <span class="dv">1</span>), (<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>), (<span class="dv">1</span>, <span class="dv">0</span>), (<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true"></a>    <span class="kw">def</span> traverse(i, j):</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true"></a>        queue <span class="op">=</span> deque([(i, j)])</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true"></a>        <span class="cf">while</span> queue:</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true"></a>            curr_i, curr_j <span class="op">=</span> queue.popleft() <span class="co">#alt: pop(0)</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true"></a>            <span class="cf">if</span> (curr_i, curr_j) <span class="kw">not</span> <span class="kw">in</span> visited:</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true"></a>                visited.add((curr_i, curr_j))</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true"></a>                <span class="co"># Traverse neighbors.</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true"></a>                <span class="cf">for</span> direction <span class="kw">in</span> directions:</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true"></a>                    next_i, next_j <span class="op">=</span> curr_i <span class="op">+</span> <span class="op">\</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true"></a>                        direction[<span class="dv">0</span>], curr_j <span class="op">+</span> direction[<span class="dv">1</span>]</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true"></a>                    <span class="cf">if</span> <span class="dv">0</span> <span class="op">&lt;=</span> next_i <span class="op">&lt;</span> rows <span class="kw">and</span> <span class="dv">0</span> <span class="op">&lt;=</span> next_j <span class="op">&lt;</span> cols:</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true"></a>                        <span class="co"># Add in your question-specific checks.</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true"></a>                        queue.append((next_i, next_j))</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(rows):</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cols):</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true"></a>            traverse(i, j)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true"></a>            </span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true"></a><span class="co"># BFS on graph represented by an adjacency list </span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true"></a>adj_list <span class="op">=</span> {</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true"></a>    <span class="st">&#39;A&#39;</span> : [<span class="st">&#39;B&#39;</span>,<span class="st">&#39;C&#39;</span>],</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true"></a>    <span class="st">&#39;B&#39;</span> : [<span class="st">&#39;A&#39;</span>, <span class="st">&#39;C&#39;</span>],</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true"></a>    <span class="st">&#39;C&#39;</span> : [<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>],</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true"></a>}</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true"></a><span class="kw">def</span> bfs(adj_list):</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true"></a>    </span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true"></a>    <span class="kw">def</span> traverse(node):</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true"></a>        queue <span class="op">=</span> deque([node])</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true"></a>        <span class="cf">while</span> queue:</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true"></a>            cur <span class="op">=</span> queue.popleft()</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true"></a>            <span class="cf">for</span> neighbor <span class="kw">in</span> adj_list[cur]:</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true"></a>                <span class="cf">if</span> neighbor <span class="kw">not</span> <span class="kw">in</span> visited:</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true"></a>                    queue.append(neighbor)</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true"></a>                    </span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true"></a>    <span class="cf">for</span> node <span class="kw">in</span> adj_list:</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true"></a>        traverse(node)</span></code></pre></div>
<h3 id="depth-first-search">Depth-First Search</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|V| + |E|)\)</span> worst case, Space Complexity: <span class="math inline">\(\mathcal{O}(|V|)\)</span></p>
<p>In depth-first search (DFS), we start at the root (or another arbitrarily selected node) and explore each branch completely before moving on to the next branch. That is, we go deep first before we go wide.</p>
<p>In general, DFS often has similar function to BFS. However, only DFS is optimal as a single-source shortest path algorithm in an unweighted graph.</p>
<p>Note that pre-order and other forms of tree traversal are a form of DFS. The key difference is that when implementing this algorithm for a graph, we must check if the node has been visited. If we don’t, we risk getting stuck in an infinite loop.</p>
<p>Again, we find that when implemented with an Adjacency List, the time complexity of DFS will be <span class="math inline">\(\mathcal{O}(|V| + |E|)\)</span>, but when implemented with an Adjacency Matrix it will be <span class="math inline">\(\mathcal{O}(|V|^2)\)</span>.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb33" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true"></a><span class="co"># Using an adjacency matrix graph representation</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true"></a><span class="kw">def</span> dfs(adj_matrix):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true"></a>    <span class="cf">if</span> <span class="kw">not</span> adj_matrix: <span class="cf">return</span> []</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true"></a>    rows, cols <span class="op">=</span> <span class="bu">len</span>(adj_matrix), <span class="bu">len</span>(adj_matrix[<span class="dv">0</span>])</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true"></a>    directions <span class="op">=</span> ((<span class="dv">0</span>, <span class="dv">1</span>), (<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>), (<span class="dv">1</span>, <span class="dv">0</span>), (<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true"></a>    <span class="kw">def</span> traverse(i, j):</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true"></a>        <span class="cf">if</span> (i, j) <span class="kw">in</span> visited:</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true"></a>            <span class="cf">return</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true"></a>        visited.add((i, j))</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true"></a>        <span class="co"># Traverse neighbors.</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true"></a>        <span class="cf">for</span> direction <span class="kw">in</span> directions:</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true"></a>            next_i, next_j <span class="op">=</span> i <span class="op">+</span> direction[<span class="dv">0</span>], j <span class="op">+</span> direction[<span class="dv">1</span>]</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true"></a>            <span class="cf">if</span> <span class="dv">0</span> <span class="op">&lt;=</span> next_i <span class="op">&lt;</span> rows <span class="kw">and</span> <span class="dv">0</span> <span class="op">&lt;=</span> next_j <span class="op">&lt;</span> cols:</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true"></a>                <span class="co"># Add in your question-specific checks.</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true"></a>                traverse(next_i, next_j)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(rows):</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cols):</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true"></a>            traverse(i, j)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true"></a><span class="co"># Using an adjacency list graph representation</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true"></a><span class="kw">def</span> dfs(adj_list):</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true"></a>    <span class="kw">def</span> traverse(node):</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true"></a>        <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> visited:</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true"></a>            visited.add(node)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true"></a>            <span class="cf">for</span> neighbour <span class="kw">in</span> adj_list[node]:</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true"></a>                traverse(neighbour)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true"></a>    <span class="cf">for</span> node <span class="kw">in</span> adj_list.keys():</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true"></a>        traverse(node)</span></code></pre></div>
<h3 id="bidirectional-search">Bidirectional Search</h3>
<p>Bidirectional search is used to find the shortest path between a source and destination node. It operates by essentially running two simultaneous breadth-first searches, one from each node. When their searches collide, we have found a path. If every node has at most <span class="math inline">\(k\)</span> adjacent nodes and the shortest path from node <span class="math inline">\(s\)</span> to node <span class="math inline">\(t\)</span> has length <span class="math inline">\(d\)</span>. Then, in a traditional breadth-first search we visit <span class="math inline">\(\mathcal{O}(k^d)\)</span> nodes while bidrectional search visits <span class="math inline">\(\mathcal{O}(k^{d/2})\)</span></p>
<h3 id="dijkstras-shortest-path-algorithm">Dijkstra’s Shortest Path Algorithm</h3>
<p>Time Complexity: <span class="math inline">\(\Theta (|E|+|V|\log |V|)\)</span> worst case</p>
<p>An algorithm for finding the shortest paths between nodes in a positive weighted, directed, acyclic graph. For a given source node in the graph, the algorithm finds the shortest path between that node and every other. Let the node at which we are starting be called the initial node and the distance of node Y be the distance from the initial node to Y. Dijkstra’s algorithm will assign some initial distance values and will try to improve them iteratively, prioritizing shorter distances and edges with low weights in its path discovery process.</p>
<p>Breadth-first search will find the path with the fewest segments. But in Dijkstra’s algorithm, you assign a number or weight to each segment. Then Dijkstra’s algorithm finds the path with the smallest total weight.</p>
<ol type="1">
<li><p>Mark all nodes unvisited and store them in a set.</p></li>
<li><p>Set the distance to zero for our initial node and to infinity for other nodes.</p></li>
<li><p>From the set of unvisited vertices, choose the vertex with the smallest distance and set it to the current node.</p></li>
<li><p>Find unvisited neighbors for the current node and calculate their distances through the current node. Compare the newly calculated distance to the assigned and save the smaller one. For example, if the node A has a distance of 6, and the A-B edge has length 2, then the distance to B through A will be 6 + 2 = 8. If B was previously marked with a distance greater than 8 then change it to 8.</p></li>
<li><p>When we are done considering all of the unvisited neighbours of the current node, mark the current node as visited and remove it from the unvisited set. A visited node will never be checked again.</p></li>
<li><p>Stop, if the destination node has been visited (when planning a route between two specific nodes) or if the smallest distance among the unvisited nodes is infinity. If not, repeat steps 3-6.</p></li>
</ol>
<p>The code for maintaining the visited set can be simplified by using a priority queue (min heap) and dictionary (hashmap) data structure for storing the graph as an adjacency list and for storing the minimum distances.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb34" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true"></a><span class="im">import</span> heapq </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true"></a>edges <span class="op">=</span> [</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true"></a>    (<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="dv">7</span>),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true"></a>    (<span class="st">&quot;A&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="dv">5</span>),</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true"></a>    (<span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="dv">8</span>),</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true"></a>    (<span class="st">&quot;D&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="dv">15</span>),</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true"></a>]</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true"></a><span class="kw">def</span> dijkstra(edges, start, end):</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true"></a>    graph <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true"></a>    <span class="cf">for</span> l, r, weight <span class="kw">in</span> edges:</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true"></a>        graph[l].append((weight, r))</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true"></a>    q <span class="op">=</span> [(<span class="dv">0</span>, start, ())] <span class="co"># queue of tuples: cumulative cost, vertex, path</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true"></a>    mins <span class="op">=</span> {start: <span class="dv">0</span>}</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true"></a>    </span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true"></a>    <span class="cf">while</span> q:</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true"></a>        (cost, v1, path) <span class="op">=</span> heapq.heappop(q)</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true"></a>        <span class="cf">if</span> v1 <span class="kw">not</span> <span class="kw">in</span> visited:</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true"></a>            visited.add(v1)</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true"></a>            path <span class="op">=</span> (v1, path)</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true"></a>            <span class="cf">if</span> v1 <span class="op">==</span> end: <span class="cf">return</span> (cost, path)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true"></a></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true"></a>            <span class="cf">for</span> weight, v2 <span class="kw">in</span> graph.get(v1, ()):</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true"></a>                <span class="cf">if</span> v2 <span class="kw">in</span> visited: <span class="cf">continue</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true"></a>                </span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true"></a>                next_cost <span class="op">=</span> cost <span class="op">+</span> weight</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true"></a>                prev_cost <span class="op">=</span> mins.get(v2, <span class="va">None</span>)</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true"></a>                <span class="cf">if</span> prev_cost <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> next_cost <span class="op">&lt;</span> prev_cost:</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true"></a>                    mins[v2] <span class="op">=</span> next_cost</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true"></a>                    heapq.heappush(q, (next_cost, v2, path))</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true"></a></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">float</span>(<span class="st">&quot;inf&quot;</span>)</span></code></pre></div>
<h3 id="a">A*</h3>
<p>A* (pronounced "A-star") is a graph traversal and path search algorithm. It is a minor extension of Djikstra’s algorithm that builds in a heuristic for remaining distance used to indicate the relevance of paths which should be tried first.</p>
<p>One important aspect of A* is <span class="math inline">\(F = G + H\)</span>. The <span class="math inline">\(F\)</span>, <span class="math inline">\(G\)</span>, and <span class="math inline">\(H\)</span> variables are in our Node class and get calculated every time we create a new node.</p>
<ul>
<li><p><span class="math inline">\(F\)</span> is the total cost of the node.</p></li>
<li><p><span class="math inline">\(G\)</span> is the distance between the current node and the start node.</p></li>
<li><p><span class="math inline">\(H\)</span> is the heuristic — estimated distance from the current node to the end node.</p></li>
</ul>
<p>A major practical drawback is its <span class="math inline">\(\mathcal{O}(b^d)\)</span> space complexity, as it stores all generated nodes in memory.</p>
<h3 id="bellman-ford-shortest-path-algorithm">Bellman-Ford Shortest Path Algorithm</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|E||V|)\)</span> worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(|V|)\)</span>.</p>
<p>The Bellman-Ford (BF) algorithm is a Single Source Shortest Path (SSSP) algorithm, i.e. it can find the shortest path from one node to any other. It is slower than Djikstra’s algorithm, but is capable of handling graph’s with negative edges, in particular negative weighted cycles.</p>
<ol type="1">
<li><p>Let <span class="math inline">\(S\)</span> be the start node and <span class="math inline">\(D\)</span> be an array of length <span class="math inline">\(|V|\)</span> to record distances. Initialized every entry in <span class="math inline">\(D\)</span> to <span class="math inline">\(\infty\)</span></p></li>
<li><p>Set <span class="math inline">\(D[S] = 0\)</span>. Traverse the graph from adjacencies of <span class="math inline">\(S\)</span> in any order.</p></li>
<li><p>Relax each edge <span class="math inline">\(V-1\)</span> times, i,e. <span class="math inline">\(D[edge.to] = min(D[edge.to], D[edge.from] + edge.cost)\)</span>.</p></li>
<li><p>After traversing the graph <span class="math inline">\(V-1\)</span> times, repeat previous step and if any edge is still updated to a new minimum then there exists a negative cycle. So we set that node to <span class="math inline">\(-\infty\)</span>.</p></li>
</ol>
<h3 id="floyd-warshall-all-pairs-shortest-path-algorithm">Floyd-Warshall All-Pairs Shortest Path Algorithm</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|V|^3)\)</span> worst case. Space Complexity: <span class="math inline">\(\mathcal{O}(|V|^2)\)</span>.</p>
<p>The Floyd-Warshall (FW) algorithm is an (All-Pairs Shortest Path) algorithm. This means it can find the shortest path between all pairs of nodes. With its high cubic time complexity, it’s generally only ideal for graphs with less than a couple hundred nodes.</p>
<p>FW works well with a 2D adjacency matrix with <span class="math inline">\(\infty\)</span> representing no adjacency. The main idea of FW is to build up all possible intermediary paths between node <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> to find the optimal path. We use dynamic programming, covered in more details later, to cache previous optimal solutions in a 3D <span class="math inline">\(n\times n\)</span> memo table.</p>
<ol type="1">
<li><p>Define <span class="math inline">\(dp\)</span> table where <span class="math inline">\(dp[i][j] =\)</span> shortest path from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> routing through nodes <span class="math inline">\(\{ 0, 1, \dots, k \}\)</span>.</p></li>
<li><p>Iterate over 3 nested loops <span class="math inline">\(k,i,j\)</span> to fill the <span class="math inline">\(dp\)</span> table.</p></li>
<li><p>Transitions will be, <span class="math inline">\(dp[i][j] =\)</span> <span class="math inline">\(m[i][j]\)</span> if <span class="math inline">\(k = 0\)</span>. Otherwise <span class="math inline">\(dp[i][j] = min(dp[i][j], dp[i][k] + dp[k-1][k][j])\)</span>. where we compute the solution for <span class="math inline">\(k\)</span> in place, saving us a dimension of space.</p>
<p>Note, the first term in the minimization is reusing the previous best distance routing through <span class="math inline">\(0, \dots, k-1\)</span>. The second term is essentially measures the path from <span class="math inline">\(i\)</span> to <span class="math inline">\(k\)</span> plus the path from <span class="math inline">\(k\)</span> to <span class="math inline">\(j\)</span>.</p></li>
<li><p>If negative cycles are possible, add a subroutine to detect them</p></li>
<li><p>Return <span class="math inline">\(dp\)</span>, the 2D matrix containing the shortest path pairs.</p></li>
</ol>
<h2 id="graph-analysis-methods">Graph Analysis Methods</h2>
<h3 id="tarjans-strongly-connected-component-algorithm">Tarjan’s Strongly Connected Component Algorithm</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|E| + |V|)\)</span> worst case.</p>
<p>A <em>strongly connected component</em> (SCC) can be thought of as self-contained cycles within a directed graph where every vertex in a given cycle can reach every other vertex in the same cycle.</p>
<p>A <em>low-link</em> of a node is the smallest node id reachable from that node where the id corresponds to a rank obtained by performing a DFS with some starting node being 0. The low-link value is highly dependent on the order of traversal in a DFS, which is random.</p>
<p>To cope with the random traversal order of a DFS, Tarjan’s algorithm maintains a stack of valid nodes from which to update low-link values from. Nodes are added to the stack of valid nodes as they’re explored for the first time and are removed each time a complete SCC is found. To update node <span class="math inline">\(u\)</span>’s low-link value to node <span class="math inline">\(v\)</span>’s low-link value, there must be a path of edges from <span class="math inline">\(u\)</span> to <span class="math inline">\(v\)</span> and <span class="math inline">\(v\)</span> must be on the stack. Then we find that each strongly connected component will contain the same low-link value.</p>
<ol type="1">
<li><p>Mark the id of each node as unvisited.</p></li>
<li><p>Perform a DFS from an arbitrary node. Upon visiting a node, assign it an id and a low-link value. Mark current nodes as visited and add them to a seen stack.</p></li>
<li><p>On DFS callback, i.e. after reaching a leaf or already vising all neighbors, we begin backtracking. If the previous node is on the seen stack, then minimize the current node’s low-link value with the last node’s low-link vaue. This allows low-link values to propegate through cycles being tracked in the stack.</p></li>
<li><p>After visiting all neighbors, if the current node started a connected component started a connected component, i.e. if its id equals its low-link value, then pop all nodes off the stack until the current node is reached. This will remove all the nodes associated with the current connected component and reset our stack reference.</p></li>
<li><p>Pick another node at random and continue this process until all nodes are visited.</p></li>
</ol>
<h3 id="prims-minimum-spanning-tree-algorithm">Prim’s Minimum Spanning Tree Algorithm</h3>
<p>Time Complexity: Varies on implementation <span class="math inline">\(\mathcal{O}(|E|\log(|V|)\)</span></p>
<p>Given an undirected, connected graph, a <strong>Minimum Spanning Tree</strong> (MST) is a subset of the edges which connects all vertices together (without creating cycles) while minimizing the total edge cost. It is possible for graphs to have multiple MSTs. In an unconnected graph, multiple sets of MSTs will form a <strong>Minimum Spanning Forrest</strong> (MSF).</p>
<p>Prim’s algorithm is a greedy MST algorithm that works well on dense graphs. On these graphs, it meets or rivals other popular MST/MSF algorithms like Kruskal’s and Boruvka’s. The lazy version of Prim’s algorithm uses a priority queue and has running time of <span class="math inline">\(\mathcal{O}(|E| \log(|E|))\)</span>, while the eager version has running time of <span class="math inline">\(\mathcal{O}(|E| \log(|V|))\)</span></p>
<p>Lazy Prim’s MST</p>
<ol type="1">
<li><p>Maintain a min Priority Queue (<span class="math inline">\(PQ\)</span>) that sorts edges based on min edge cost. This will be used to determine the next node to visit and the edges used to get there.</p></li>
<li><p>Start the algorthm on any node <span class="math inline">\(s\)</span>. Mark <span class="math inline">\(s\)</span> as visited and iterate over all edges of <span class="math inline">\(s\)</span>, adding them to <span class="math inline">\(PQ\)</span>.</p></li>
<li><p>While the <span class="math inline">\(PQ\)</span> is not empty and MST has not been formed, dequeue the next cheapest edge from <span class="math inline">\(PQ\)</span>. If the dequeued edge is stale, i.e. it has already be visited, then skip it and poll again. Otherwise mark the current node as visited and add it to the MST.</p></li>
<li><p>Iterate over the new current node’s edges and add all its edges to the <span class="math inline">\(PQ\)</span>. Do not add edges to the <span class="math inline">\(PQ\)</span> which point to already visited nodes.</p></li>
</ol>
<p>In the eager version, instead of adding edges to the priority queue as we iterate over the edges of a node, we update the destinations node’s most promising incoming edge. We do this using an indexed priorty queue (IPQ).</p>
<h3 id="kruskals-minimum-spanning-tree-algorithm">Kruskal’s Minimum Spanning Tree Algorithm</h3>
<p>Complexity: <span class="math inline">\(\mathcal{O}(|E|\log(|V|)\)</span></p>
<ol type="1">
<li><p>Sort edges by ascending edge weight.</p></li>
<li><p>Walk through sorted edges and look at the two nodes the edges belong to. If the nodes area already unified we don’t include this edge, otherwise we include and unify the nodes. Unified edges are groupings of sub-trees in the graph. The algorithm makes use of the <em>union find</em> data structure to efficiently determine if an edge belongs to an existing group.</p></li>
<li><p>The algorithm terminates when every edge has been processed or all the vertices have been unified.</p></li>
</ol>
<h3 id="topological-sort">Topological Sort</h3>
<p>Time Complexity: <span class="math inline">\(\mathcal{O}(|V| + |E|)\)</span> worst case, Space Complexity: <span class="math inline">\(\mathcal{O}(|V|)\)</span></p>
<p>A topological sort or topological ordering of a directed graph is a linear ordering of its vertices such that for every directed edge <span class="math inline">\(uv\)</span> from vertex <span class="math inline">\(u\)</span> to vertex <span class="math inline">\(v\)</span>, <span class="math inline">\(u\)</span> comes before <span class="math inline">\(v\)</span> in the ordering. A topological ordering is possible if and only if the graph has no directed cycles, that is, if it is a <strong>directed acyclic graph</strong> (DAG). Any DAG has at least one topological ordering, and algorithms are known for constructing a topological ordering of any DAG in linear time. A simple way to understand a topological ordering is to visualize the graph with each node placed in a row such that edges are only directed to the right.</p>
<p>An algorithm for topological sorting is based on depth-first search. Simply put, run DFS and output the reverse of the finishing times of vertices, where finishing time corresponds to number of steps taken by DFS. The algorithm loops through each node of the graph, in an arbitrary order, initiating a depth-first search that terminates when it hits any node that has already been visited since the beginning of the topological sort or the node has no outgoing edges (i.e. a leaf node). Each node <span class="math inline">\(n\)</span> gets prepended to the output list <span class="math inline">\(L\)</span> only after considering all other nodes which depend on <span class="math inline">\(n\)</span> (all descendants of <span class="math inline">\(n\)</span> in the graph). Specifically, when the algorithm adds node <span class="math inline">\(n\)</span>, we are guaranteed that all nodes which depend on <span class="math inline">\(n\)</span> are already in the output list <span class="math inline">\(L\)</span>: they were added to <span class="math inline">\(L\)</span> either by the recursive call to visit() which ended before the call to visit <span class="math inline">\(n\)</span>, or by a call to visit() which started even before the call to visit <span class="math inline">\(n\)</span>. Since each edge and node is visited once, the algorithm runs in linear time.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb35" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> deque</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true"></a>IN_PROGRESS, COMPLETE <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true"></a><span class="kw">def</span> topological_sort(graph):</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true"></a>    order, enter, state <span class="op">=</span> deque(), <span class="bu">set</span>(graph), {}</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true"></a>        state[node] <span class="op">=</span> IN_PROGRESS</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true"></a>        <span class="cf">for</span> k <span class="kw">in</span> graph.get(node, ()):</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true"></a>            sk <span class="op">=</span> state.get(k, <span class="va">None</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true"></a>            <span class="cf">if</span> sk <span class="op">==</span> IN_PROGRESS:</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;cycle&quot;</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true"></a>            <span class="cf">if</span> sk <span class="op">==</span> COMPLETE:</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true"></a>                <span class="cf">continue</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true"></a>            enter.discard(k)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true"></a>            dfs(k)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true"></a>        order.appendleft(node)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true"></a>        state[node] <span class="op">=</span> COMPLETE</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true"></a>    <span class="cf">while</span> enter:</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true"></a>        dfs(enter.pop())</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true"></a>    <span class="cf">return</span> order</span></code></pre></div>
<h2 id="recursive-problems">Recursive Problems</h2>
<p>We can interpret recursive solutions using the following categories:</p>
<ul>
<li><p>A <strong>bottom-up</strong> approach is often the most intuitive recursive pattern. We start with knowing how to solve the problem for a simple case, like a list with only one element. Then we figure out how to solve the problem for two elements, then for three elements, and so on. The key here is to think about how you can build the solution for one case off of the previous case (or multiple previous cases).</p></li>
<li><p>The <strong>top-down</strong> approach can be more complex since it’s less concrete. But sometimes, it’s the best way to think about the problem. In these problems, we think about how we can divide the problem for case <span class="math inline">\(N\)</span> into subproblems. Be careful of overlap between the cases.</p></li>
<li><p>The <strong>half-and-half</strong> approach: in addition to top-down and bottom-up approaches, it’s often effective to divide the data set in half. For example, binary search works with a "half-and-half" approach. When we look for an element in a sorted array, we first figure out which half of the array contains the value. Then we recurse and search for it in that half.</p></li>
</ul>
<p>A problem is said to have <strong>overlapping subproblems</strong> if the problem can be broken down into subproblems which are reused several times or a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems. For example, consider the recursive generation of the <span class="math inline">\(n\)</span>th Fibonacci number.</p>
<p>A problem is said to have <strong>optimal substructure</strong> if an optimal solution can be constructed efficiently from optimal solutions of its subproblem. Another way to view this is that when given the optimal solution, the solution of the sub-problems will also be optimal. For example: if we know a path (A, B, C, D) is the shortest possible distance between A and D, then the shortest path from B to D must also pass through C.</p>
<h3 id="the-dag-model">The DAG Model</h3>
<p>Many problems involve finding a solution by processing the state space, i.e. the space of all possible results, in order to find the optimal result. An algorithm processes the state space by making a series of decisions and completes when it knows it has found the best resulting set of decisions. We can think of this decision space in terms of a graph structure in which each node being traversed is an inclusion to our resulting decision sequence which is represented by a path. Then, each of the outgoing edges in the graph indicates a reachable link from one state to another.</p>
<p>Recall that a <strong>directed acyclic graph (DAG)</strong> is a directed graph that does not contain any cycles. This can be understood as a state space in which no decision chosen from a unique subset of choices can be reached again or included multiple times, i.e. there are no infinite loops.</p>
<ol type="1">
<li><p><strong>Depth-First Search</strong> – In the most straightforward case, we are given a generic state space represented as a directed graph that may or may not be acyclic and we want to determine whether two states are reachable from one another.</p>
<p>DFS is the ideal solution since no heuristic is available as the intermediary states do not reveal information about the location of the desired state, except when it is found or unreachable as a result visiting all neighbors or reaching a leaf node without neighbors. Although overlapping subproblems exist, i.e. the state space has statically defined adjacent edges, we can not optimize the final result through a heuristic made in the aglorithm’s local decisions. Despite doing some bookkeeping, we are mostly blindly searching the state space.</p></li>
<li><p><strong>Backtracking</strong> – Similar to DFS, this approach can be used when there are overlapping subproblems but no optimal substructure, i.e. we can not derive optimal solutions to subproblems even when given a global optimal solution. Additionally no local cost analysis can be performed independent of previous states. However, when analysing a current state and its previous states, a heuristic exists that determines if a path cannot possibly be appended to produce a valid solution. So that a path can be avoided or pruned without reaching its leaves as is necessary in DFS.</p></li>
<li><p><strong>Greedy Algorithm</strong> – This approach is ideal when overlapping subproblems exist and a cost analysis exists in which making optimal local decisions results in finding the globally optimal result. Moreover, the cost analysis heuristic is independent of previous states and only involves processing the subset of decisions at the current local state.</p></li>
<li><p><strong>Dynamic Programming</strong> – Similar to the greedy algorithm, this approach is ideal when there are overlapping subproblems and optimal substructure exists, i.e. given the optimal solution, sub-problems will also be optimal. Although a greedy heuristic may also solve some problems with optimal substructure, a DP approach is more reliable when cost analysis is largely dependent on previous decision states.</p></li>
</ol>
<h3 id="backtracking">Backtracking</h3>
<p>Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions and abandons a candidate as soon as it determines that the candidate cannot possibly be completed to a valid solution.</p>
<p>It is useful for exhaustive recursive problems in which the solution must follow some constraints. We may define a policy for recursion and when a computation does not meet the constraints, we halt or backtrack on the exhaustive recursion. The call stack remembers our previous choices and decides what choice to make next.</p>
<p>Three key things to keep in mind</p>
<ol type="1">
<li><p>Our choice – What choice do we make at each call of the function? Recursion expresses this decision</p></li>
<li><p>Our constraints – When do we stop following a certain path?</p></li>
<li><p>Our goal – What’s our target? What are we trying to find?</p></li>
</ol>
<p>The difference between backtracking and depth-first search is that backtracking traverses in the solution space whereas DFS traverses in data structure space. DFS is a special type of backtracking paradigm where the process of backtracking only takes place in the leaf nodes whereas general backtracking algorithms can also preemptively reject useless branches of the state space tree. Thus, DFS maintains the entire tree structure while backtracking creates a pruned tree.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb36" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true"></a><span class="kw">def</span> backtrack(candidate):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true"></a>    <span class="cf">if</span> find_solution(candidate):</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true"></a>        <span class="cf">return</span> candidate</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true"></a>    </span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true"></a>    <span class="co"># iterate all possible candidates.</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true"></a>    <span class="cf">for</span> next_candidate <span class="kw">in</span> list_of_candidates:</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true"></a>        <span class="cf">if</span> is_valid(next_candidate):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true"></a>            <span class="co"># try this partial candidate solution</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true"></a>            place(next_candidate)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true"></a>            <span class="co"># given the candidate, explore further.</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true"></a>            backtrack(next_candidate)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true"></a>            <span class="co"># backtrack/prune</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true"></a>            remove(next_candidate)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true"></a>            </span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true"></a><span class="co">## Generate all combinations of well-formed parentheses with n pairs.</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true"></a><span class="kw">def</span> generate_parenthesis(n):</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true"></a>    ans <span class="op">=</span> []</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true"></a>    <span class="kw">def</span> backtrack(S<span class="op">=</span><span class="st">&#39;&#39;</span>, left<span class="op">=</span><span class="dv">0</span>, right<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true"></a>        <span class="cf">if</span> <span class="bu">len</span>(S) <span class="op">==</span> <span class="dv">2</span> <span class="op">*</span> n:</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true"></a>            ans.append(S)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true"></a>            <span class="cf">return</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true"></a>        <span class="cf">if</span> left <span class="op">&lt;</span> n:</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true"></a>            backtrack(S <span class="op">+</span> <span class="st">&quot;(&quot;</span>, left <span class="op">+</span> <span class="dv">1</span>, right)</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true"></a>        <span class="cf">if</span> right <span class="op">&lt;</span> left:</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true"></a>            backtrack( S <span class="op">+</span> <span class="st">&quot;)&quot;</span>, left, right <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true"></a>    backtrack()    </span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true"></a>    <span class="cf">return</span> ans</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true"></a>    </span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true"></a><span class="cf">assert</span> generate_parenthesis(<span class="dv">3</span>) <span class="op">==</span> [</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true"></a>  <span class="st">&quot;((()))&quot;</span>,</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true"></a>  <span class="st">&quot;(()())&quot;</span>,</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true"></a>  <span class="st">&quot;(())()&quot;</span>,</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true"></a>  <span class="st">&quot;()(())&quot;</span>,</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true"></a>  <span class="st">&quot;()()()&quot;</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true"></a>]</span></code></pre></div>
<h3 id="greedy-algorithms">Greedy Algorithms</h3>
<p>A greedy algorithm, as the name suggests, always makes the choice that seems to be the best at that moment. This means that it makes a locally-optimal choice in the hope that this choice will lead to a globally-optimal solution. They never look backwards at what they’ve done to see if they could optimise globally. This is the main difference between Greedy and Dynamic Programming.</p>
<p>Even though a greedy algorithm follows the problem-solving heuristic of making the locally optimal choice at each stage with the intent of finding a global optimum, there are cases where locally optimal solutions or maxima are not the global optimal solution which will cause the algorithm to product incorrect solutions. Nonetheless a greedy heuristic may yield locally optimal solutions that approximate a globally optimal solution in a reasonable amount of time.</p>
<p>Greedy algorithms are only ideal for problems which have optimal substructure. Typically, a greedy algorithm is used to solve a problem with optimal substructure if it can be proven by induction that it is optimal at each step. Otherwise, provided the problem exhibits overlapping subproblems, then dynamic programming is preferable. If there are no appropriate greedy algorithms and the problem fails to exhibit overlapping subproblems, often a lengthy but straightforward search of the solution space is the best alternative. If the problem is NP-Complete, a greedy algorithm is likely the best approximation function.</p>
<h3 id="dynamic-programming-memoization">Dynamic Programming &amp; Memoization</h3>
<p>Dynamic programming (DP) is a general, powerful algorithm design technique. It is mostly just a matter of taking a recursive algorithm and finding the overlapping subproblems (that is, the repeated calls). You then cache those results for future recursive calls. Alternatively, you can study the pattern of the recursive calls and implement something iterative. You still cache previous work. A dynamic programming solution can only be used if the problem possesses the optimal substructure property, i.e. its global optimal solution can be constructed efficiently from optimal solutions of its subproblems. Recall, overlapping subproblems exist if the problem can be broken down into subproblems which are reused several times.</p>
<p>DP corresponds to a careful bruteforce approach, taking an exponential algorithm and making it polynomial. The basic idea of dynamic programming is to take a problem, split it into subproblems, solve the subproblems, and re-use the solutions to the subproblems.</p>
<p><strong>Memoization</strong> refers to the technique of caching and reusing previously computed results. Some people call top-down dynamic programming “memoization” and only use "dynamic programming" to refer to bottom-up work</p>
<p>A bottom-up solution uses <strong>tabulation</strong> to only store the relevant calls needed for future computations. With tabulation, we have to come up with an ordering which is often less intuitive than memoized solutions. If all sub-problems must be solved at least once, a bottom-up tabulated dynamic programming algorithm usually outperforms a top-down memoized algorithm by a constant factor.</p>
<p>A memoized function only recurses the first time it’s called with the memoized call costing <span class="math inline">\(\Theta(1)\)</span>. In general, the time complexity will be the number of subproblems needed to be solved multiplied by the running time per subproblem. We no longer need to count recursions or the call stack.</p>
<p>Subproblems for strings or arrays will be one of the following:</p>
<ul>
<li><p><strong>Suffixes</strong> – x[i:] for all i. Time complexity: <span class="math inline">\(\mathcal{O}(n)\)</span></p></li>
<li><p><strong>Prefixes</strong> – x[:i] for all i. Time complexity: <span class="math inline">\(\mathcal{O}(n)\)</span></p></li>
<li><p><strong>Substrings</strong> – x[i:j] for all <span class="math inline">\(i \leq j\)</span>. Time complexity: <span class="math inline">\(\mathcal{O}(n^2)\)</span></p></li>
</ul>
<p>A useful strategy for solving dynamic programming problems is as follows:</p>
<ol type="1">
<li><p>Define subproblems.</p></li>
<li><p>Guess part of the solution.There are two kinds of guessing:</p>
<ol type="1">
<li><p>Which existing subproblems to use to solve bigger subproblem.</p></li>
<li><p>Or add more subproblems to guess, remember more features of the solution variations.</p></li>
</ol></li>
<li><p>Relate subproblem solutions with a recurrence.</p></li>
<li><p>Construct an algorithm by recursion and memoization (need acyclic DAG) or building a DP table bottom up (need topological order). Note: The topological order, i.e. the order in which subproblems are executed, should be from smallest to largest.</p></li>
<li><p>Solve original problem. The runtime will be the number of subproblems multiplied by the running time per subproblem.</p></li>
</ol>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb37" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true"></a><span class="co"># It takes n steps to reach to the top of a set of stairs. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true"></a><span class="kw">def</span> climbStairs(n): <span class="co">## Fibonacci</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true"></a>    dp <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, n <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true"></a>        dp.append(dp[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> dp[i<span class="op">-</span><span class="dv">2</span>])</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true"></a>    <span class="cf">return</span> dp[n]</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true"></a><span class="co"># Compute the fewest number of coins that are needed to sum to an amount</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true"></a><span class="kw">def</span> coinChange(coins, amount):</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true"></a>    MAX <span class="op">=</span> <span class="bu">float</span>(<span class="st">&quot;inf&quot;</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true"></a>    dp <span class="op">=</span> [<span class="dv">0</span>] <span class="op">+</span> [MAX] <span class="op">*</span> amount</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, amount <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true"></a>        dp[i] <span class="op">=</span> <span class="bu">min</span>(dp[i <span class="op">-</span> c] <span class="cf">if</span> i <span class="op">-</span> c <span class="op">&gt;=</span> <span class="dv">0</span> <span class="cf">else</span> MAX <span class="cf">for</span> c <span class="kw">in</span> coins) <span class="op">+</span> <span class="dv">1</span> </span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true"></a>        </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true"></a>    <span class="cf">return</span> dp[<span class="op">-</span><span class="dv">1</span>] <span class="cf">if</span> dp[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> MAX <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true"></a>    <span class="co"># return [dp[-1], -1][dp[-1] == MAX]</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true"></a>    </span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true"></a><span class="co"># Given a knapsack with a maximum weight capacity and a list of items with value and weights, maximize the amount of value we can fit within the knapsacks weight capacity.</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true"></a><span class="kw">def</span> knapsack(capacity, weight, values, n):</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true"></a>    <span class="cf">if</span> n <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> capacity <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true"></a>        <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true"></a>    <span class="co"># If weight is higher than capacity then it is not included</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true"></a>    <span class="cf">if</span> (weight[n<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> capacity):</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true"></a>        <span class="cf">return</span> knapsack(capacity, weight, values, n<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true"></a>    <span class="co"># return either nth item being included or not</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true"></a>    <span class="cf">else</span>:</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true"></a>        <span class="cf">return</span> <span class="bu">max</span>(</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true"></a>            values[n<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> knapsack(capacity<span class="op">-</span>weight[n<span class="op">-</span><span class="dv">1</span>], weight, values, n<span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true"></a>            knapsack(capacity, weight, values, n<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true"></a></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true"></a><span class="co"># Given an unsorted array of integers, find the length of longest increasing subsequence.</span></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true"></a></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true"></a><span class="kw">def</span> lis(nums):</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true"></a>    n <span class="op">=</span> <span class="bu">len</span>(nums)</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true"></a>    <span class="cf">if</span> <span class="kw">not</span> n: <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true"></a>    dp <span class="op">=</span> [<span class="dv">1</span>] <span class="op">*</span> n</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true"></a></span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true"></a>            <span class="cf">if</span> nums[i] <span class="op">&gt;</span> nums[j]:</span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true"></a>                dp[i] <span class="op">=</span> <span class="bu">max</span>(dp[i], dp[j]<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true"></a></span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">max</span>(dp)</span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true"></a><span class="co"># Given two strings text1 and text2, return the length of their longest common subsequence.</span></span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true"></a></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true"></a><span class="im">import</span> functools</span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true"></a><span class="kw">def</span> lcs_cache(text1: <span class="bu">str</span>, text2: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true"></a>    <span class="co">## similar to memoization, in recursive calls the decorator doesn&#39;t have to recompute but retrieves from the cache</span></span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true"></a>    <span class="at">@functools.lru_cache</span>(<span class="va">None</span>)</span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true"></a>    <span class="kw">def</span> helper(i,j):</span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true"></a>        <span class="cf">if</span> i<span class="op">&lt;</span><span class="dv">0</span> <span class="kw">or</span> j<span class="op">&lt;</span><span class="dv">0</span>:</span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true"></a>            <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true"></a>        <span class="cf">if</span> text1[i]<span class="op">==</span>text2[j]:</span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true"></a>            <span class="cf">return</span> helper(i<span class="op">-</span><span class="dv">1</span>,j<span class="op">-</span><span class="dv">1</span>)<span class="op">+</span><span class="dv">1</span></span>
<span id="cb37-60"><a href="#cb37-60" aria-hidden="true"></a>        <span class="cf">return</span> <span class="bu">max</span>(helper(i<span class="op">-</span><span class="dv">1</span>,j),helper(i,j<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb37-61"><a href="#cb37-61" aria-hidden="true"></a>    <span class="cf">return</span> helper(<span class="bu">len</span>(text1)<span class="op">-</span><span class="dv">1</span>,<span class="bu">len</span>(text2)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-62"><a href="#cb37-62" aria-hidden="true"></a></span>
<span id="cb37-63"><a href="#cb37-63" aria-hidden="true"></a><span class="kw">def</span> lcs_table(X, Y): </span>
<span id="cb37-64"><a href="#cb37-64" aria-hidden="true"></a>    m <span class="op">=</span> <span class="bu">len</span>(X) </span>
<span id="cb37-65"><a href="#cb37-65" aria-hidden="true"></a>    n <span class="op">=</span> <span class="bu">len</span>(Y) </span>
<span id="cb37-66"><a href="#cb37-66" aria-hidden="true"></a>    L <span class="op">=</span> [[<span class="va">None</span>]<span class="op">*</span>(n <span class="op">+</span> <span class="dv">1</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m <span class="op">+</span> <span class="dv">1</span>)] </span>
<span id="cb37-67"><a href="#cb37-67" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m <span class="op">+</span> <span class="dv">1</span>): </span>
<span id="cb37-68"><a href="#cb37-68" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n <span class="op">+</span> <span class="dv">1</span>): </span>
<span id="cb37-69"><a href="#cb37-69" aria-hidden="true"></a>            <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> j <span class="op">==</span> <span class="dv">0</span> : </span>
<span id="cb37-70"><a href="#cb37-70" aria-hidden="true"></a>                L[i][j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb37-71"><a href="#cb37-71" aria-hidden="true"></a>            <span class="cf">elif</span> X[i<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> Y[j<span class="op">-</span><span class="dv">1</span>]: </span>
<span id="cb37-72"><a href="#cb37-72" aria-hidden="true"></a>                L[i][j] <span class="op">=</span> L[i<span class="op">-</span><span class="dv">1</span>][j<span class="op">-</span><span class="dv">1</span>]<span class="op">+</span><span class="dv">1</span></span>
<span id="cb37-73"><a href="#cb37-73" aria-hidden="true"></a>            <span class="cf">else</span>:</span>
<span id="cb37-74"><a href="#cb37-74" aria-hidden="true"></a>                L[i][j] <span class="op">=</span> <span class="bu">max</span>(L[i<span class="op">-</span><span class="dv">1</span>][j], L[i][j<span class="op">-</span><span class="dv">1</span>]) </span>
<span id="cb37-75"><a href="#cb37-75" aria-hidden="true"></a>    <span class="cf">return</span> L[m][n] </span></code></pre></div>
<h2 id="numerical-problems">Numerical Problems</h2>
<h3 id="bit-manipulation">Bit Manipulation</h3>
<p>1 byte comprises of 8 bits. Any integer or character can be represented using bits, which we call its binary form (containing only 1 or 0) or its base 2 representation.</p>
<p>For example, <span class="math inline">\(14 = (1110)_2 = = 1 * 2^3 + 1 * 2^2 + 1 * 2^1 + 0 * 2^0\)</span></p>
<p>At the heart of bit manipulation are the bit-wise operators:</p>
<ul>
<li><p><strong>AND</strong> – <span class="math inline">\(\And\)</span></p>
<p><span class="math inline">\(A = 5 = (101)_2\)</span>, <span class="math inline">\(B = 3 = (011)_2\)</span></p>
<p><span class="math inline">\(A \And B = (101)_2 \And (011)_2 = (001)_2 = 1\)</span></p></li>
<li><p><strong>OR</strong> – <span class="math inline">\(\vert\)</span></p>
<p><span class="math inline">\(A = 5 = (101)_2 , B = 3 = (011)_2\)</span></p>
<p><span class="math inline">\(A \vert B = (101)_2 \  \vert \ (011)_2 = (111)_2 = 7\)</span></p></li>
<li><p><strong>NOT</strong> – <span class="math inline">\(\sim\)</span></p>
<p><span class="math inline">\(N = 5 = (101)_2\)</span></p>
<p><span class="math inline">\(\sim N = \sim 5 = \sim (101)_2 = (010)_2 = 2\)</span></p></li>
<li><p><strong>XOR</strong> – <span class="math inline">\(\wedge\)</span></p>
<p>The exclusive-or operation takes two inputs and returns a 1 if either one or the other of the inputs is a 1, but not if both are.</p>
<p><span class="math inline">\(A = 5 = (101)_2 , B = 3 = (011)_2\)</span></p>
<p><span class="math inline">\(A \wedge B = (101)_2 \wedge (011)_2 = (110)_2 = 6\)</span></p></li>
<li><p><strong>SHIFT</strong> – a <span class="math inline">\(&lt;&lt;\)</span> b, a <span class="math inline">\(&gt;&gt;\)</span> b</p>
<p>Left shift operator shifts some number of bits to the left and appends 0 at the end. Left shift is equivalent to multiplying the bit pattern with <span class="math inline">\(2^k\)</span> (if we are shifting <span class="math inline">\(k\)</span> bits ).</p>
<p><span class="math inline">\(1 &lt;&lt; n = 2^n\)</span></p>
<p>Right shift operator shifts some number of bits, to the right and appends 1 at the end. Right shift is equivalent to dividing the bit pattern by <span class="math inline">\(2k\)</span> (if we are shifting <span class="math inline">\(k\)</span> bits).</p>
<p><span class="math inline">\(16 &gt;&gt; 4 = 1\)</span></p></li>
<li><p><strong>Set a bit</strong> – <span class="math inline">\(A \vert= 1 &lt;&lt; \text{bit}\)</span></p>
<p><span class="math inline">\((1 &lt;&lt; n)\)</span> will return a number with only nth bit set. So if we OR it with <span class="math inline">\(x\)</span> it will set the nth bit of <span class="math inline">\(x\)</span>.</p></li>
<li><p><strong>Clear bit</strong> – <span class="math inline">\(A \And = \sim (1 &lt;&lt; \text{bit})\)</span></p></li>
<li><p><strong>Test bit</strong> – <span class="math inline">\((A \And 1 &lt;&lt; \text{bit}) != 0\)</span></p></li>
<li><p><strong>Extract last bit</strong> – <span class="math inline">\(A\And-A\)</span> or <span class="math inline">\(A \And \sim (A-1)\)</span> or <span class="math inline">\(x\wedge (x \And (x -1))\)</span></p>
<p><span class="math inline">\((-x)\)</span> is the two’s complement of <span class="math inline">\(x\)</span> and will have all the bits flipped that are on the left of the rightmost 1 in <span class="math inline">\(x\)</span>. So <span class="math inline">\(x \And (-x)\)</span> will return rightmost 1.</p></li>
<li><p><strong>Remove last bit</strong> – <span class="math inline">\(A \And (A-1)\)</span></p></li>
<li><p><strong>Get all 1-bits</strong> – <span class="math inline">\(\sim 0\)</span></p></li>
</ul>
<p>A big advantage of bit manipulation is that it can help to iterate over all the subsets of an N-element set. If we represent each element in a subset with a bit, which can be either 0 or 1, we can use a bit array to denote whether a corresponding element belongs to this given subset or not. Then, each bit pattern will represent a possible subset and set operations can be performed with bit operations. Basic operations are outlined below,</p>
<ul>
<li><p><strong>Set union</strong> – <span class="math inline">\(A \vert B\)</span></p></li>
<li><p><strong>Set intersection</strong> – <span class="math inline">\(A \And B\)</span></p></li>
<li><p><strong>Set subtraction</strong> – <span class="math inline">\(A \And \sim B\)</span></p></li>
<li><p><strong>Set negation</strong> – <span class="math inline">\(\text{ALL BITS } \wedge A\)</span> or <span class="math inline">\(\sim A\)</span></p></li>
</ul>
<p>Basic use cases of bit manipulations are given below,</p>
<ol type="1">
<li><p><strong>Check if a given number <span class="math inline">\(x\)</span> is a power of 2</strong> –</p>
<p>The binary representation of <span class="math inline">\((x-1)\)</span> will have all the same bits as <span class="math inline">\(x\)</span> except for the rightmost <span class="math inline">\(1\)</span> in <span class="math inline">\(x\)</span> and all the bits to the right of the rightmost <span class="math inline">\(1\)</span>.</p>
<p>Thus, <span class="math inline">\(x \And (x-1)\)</span> will have all the bits equal to the <span class="math inline">\(x\)</span> except for the rightmost <span class="math inline">\(1\)</span> in <span class="math inline">\(x\)</span>.</p>
<p>If the number is neither zero nor a power of two, it will have 1 in more than one place. So if <span class="math inline">\(x\)</span> is a power of 2 then <span class="math inline">\(x \And (x-1)\)</span> will be 0.</p>
<p><span class="math inline">\(x = 4 = (100)_2\)</span></p>
<p><span class="math inline">\(x - 1 = 3 = (011)_2\)</span></p>
<p><span class="math inline">\(x \And (x-1) = 4 \And 3 = (100)_2 \And (011)_2 = (000)_2\)</span></p></li>
<li><p><strong>Count the number of ones in the binary representation of the given number</strong> –</p>
<p>Recall, <span class="math inline">\((x-1)\)</span> has the rightmost <span class="math inline">\(1\)</span> and all bits to the right of it are flipped in comparison to <span class="math inline">\(x\)</span>. So, setting <span class="math inline">\(x = x \And (x-1)\)</span> will reduce the number of 1 bits by 1. We may do this repeatedly while incrementing a counter until <span class="math inline">\(x = 0\)</span>.</p></li>
<li><p><strong>Find the largest power of 2 which is less than or equal to the given number N</strong> –</p>
<p>Change all the bits which are at the right side of the most significant digit to 1. Then the number will become <span class="math inline">\(x + (x-1) = 2 * x -1\)</span> , where <span class="math inline">\(x\)</span> is the required answer.</p>
<p>For a 16 bit integer, <span class="math inline">\(N = N| (N&gt;&gt;1);  N = N| (N&gt;&gt;2);  N = N| (N&gt;&gt;4);  N = N| (N&gt;&gt;8); \text{ return } (N+1)&gt;&gt;1\)</span></p></li>
</ol>
<p><strong>Two’s complement</strong> is a mathematical operation on binary numbers, and is an example of a radix complement. The two’s complement is calculated by inverting the digits and adding one. The two’s complement of an N-bit number is defined as its complement with respect to <span class="math inline">\(2^N\)</span>. For instance, for the three-bit number 010, the two’s complement is 110, because 010 + 110 = 1000.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb38" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true"></a>a <span class="op">=</span> <span class="bu">set</span>([<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>])</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true"></a>b <span class="op">=</span> <span class="bu">set</span>([<span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>, <span class="st">&#39;e&#39;</span>, <span class="st">&#39;f&#39;</span>])</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true"></a>c <span class="op">=</span> <span class="bu">set</span>([<span class="st">&#39;a&#39;</span>, <span class="st">&#39;c&#39;</span>])</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true"></a><span class="co">## Union</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true"></a><span class="bu">print</span>(a <span class="op">|</span> b)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true"></a><span class="bu">print</span>(a.union([<span class="st">&quot;foo&quot;</span>, <span class="st">&quot;bar&quot;</span>]))</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true"></a><span class="co">## Intersection</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true"></a><span class="bu">print</span>(a <span class="op">&amp;</span> b)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true"></a><span class="bu">print</span>(a.intersection([<span class="st">&quot;b&quot;</span>]))</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true"></a><span class="co">## Difference</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true"></a><span class="bu">print</span>(a <span class="op">-</span> b)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true"></a><span class="bu">print</span>(a.difference([<span class="st">&quot;foo&quot;</span>]))</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true"></a></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true"></a><span class="co">## Subset</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true"></a><span class="bu">print</span>(c <span class="op">&lt;</span> a)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true"></a><span class="bu">print</span>(a.issubset([<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>, <span class="st">&quot;d&quot;</span>, <span class="st">&quot;e&quot;</span>, <span class="st">&quot;f&quot;</span>]))</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true"></a></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true"></a><span class="co">## Symmetric Difference</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true"></a><span class="bu">print</span>(a <span class="op">^</span> b) <span class="co"># {&#39;e&#39;, &#39;a&#39;, &#39;b&#39;, &#39;f&#39;}</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true"></a><span class="bu">print</span>(a.symmetric_difference([<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>, <span class="st">&quot;e&quot;</span>]))</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true"></a><span class="bu">print</span>(a.issuperset([<span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>]))</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true"></a><span class="bu">print</span>(a.isdisjoint([<span class="st">&quot;y&quot;</span>, <span class="st">&#39;z&#39;</span>]))</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true"></a>a.intersection_update([<span class="st">&quot;a&quot;</span>, <span class="st">&quot;c&quot;</span>, <span class="st">&quot;z&quot;</span>])</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true"></a><span class="bu">print</span>(a)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true"></a></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true"></a><span class="co"># Given an array containing n distinct numbers taken from [0, n], find the one that is missing from the array.</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true"></a><span class="im">import</span> operator</span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true"></a><span class="kw">def</span> missingNumber(<span class="va">self</span>, nums):</span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">reduce</span>(operator.xor, nums <span class="op">+</span> <span class="bu">range</span>(<span class="bu">len</span>(nums)<span class="op">+</span><span class="dv">1</span>))</span></code></pre></div>
<h2 id="combinatorial-problems">Combinatorial Problems</h2>
<p>View combinatorics notebook<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> for more details.</p>
<h3 id="permuations">Permuations</h3>
<ol type="1">
<li><p>Order of items matters.</p></li>
<li><p>Counts do not include duplication or removals of items.</p></li>
<li><p>Collection of counts could be stored in <em>arrays</em>.</p></li>
</ol>
<p><span class="math display">\[P(n,m) = \frac{n!}{(n-m)!}\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb39" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true"></a><span class="im">from</span> itertools <span class="im">import</span> permutations </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true"></a><span class="co"># Get all permutations of [1, 2, 3] </span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true"></a>perm <span class="op">=</span> permutations([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])   </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true"></a><span class="co"># Get all permutations of length 2 </span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true"></a>perm <span class="op">=</span> permutations([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], <span class="dv">2</span>) </span></code></pre></div>
<h3 id="combinations">Combinations</h3>
<ol type="1">
<li><p>Order of items doesn’t matter.</p></li>
<li><p>Counts do not include duplication or removals of items.</p></li>
<li><p>Collection of counts could be stored in <em>sets</em>.</p></li>
</ol>
<p><span class="math display">\[C(n, k) = \binom{n}{k} = \frac{P(n,k)}{k!} = \frac{n!}{k!(n-k)!} = \binom{n}{n-k}\]</span></p>
<p><span class="math display">\[\binom{n+1}{k} = \binom{n}{k} + \binom{n}{k+1}\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb40" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true"></a><span class="im">import</span> itertools</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true"></a><span class="co"># Get all combinations of [1, 2, 3] of length 2 </span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true"></a>comb <span class="op">=</span> itertools.combinations([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], <span class="dv">2</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true"></a><span class="co"># Get all combinations with an element-to-itself combination included </span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true"></a>comb <span class="op">=</span> itertools.combinations_with_replacement([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span></code></pre></div>
<h3 id="cartesian-product">Cartesian Product</h3>
<p>The Cartesian product of two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, is the set of all ordered pairs <span class="math inline">\((a, b)\)</span> where <span class="math inline">\(a \in A\)</span> and <span class="math inline">\(b \in B\)</span>.</p>
<div class="sourceCode" id="cb41" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true"></a><span class="im">import</span> itertools</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true"></a>A <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true"></a>B <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true"></a><span class="co"># product of two iterables taking one element from each</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true"></a><span class="co">## Using nested for loop</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true"></a><span class="cf">for</span> a <span class="kw">in</span> A: </span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true"></a>    <span class="cf">for</span> b <span class="kw">in</span> B:</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true"></a>        results.append((a, b))</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true"></a><span class="co">## Using itertools module</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true"></a><span class="co"># product of iterable with itself of size 2</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true"></a><span class="bu">list</span>(itertools.product(A, repeat<span class="op">=</span><span class="dv">2</span>))</span></code></pre></div>
<h3 id="n-th-partial-sum">n-th Partial Sum</h3>
<p>This counting formula can be used to count the number of contiguous substrings in a string or contiguous subarrays in an array. <span class="math display">\[\sum_{k=1}^n k = 1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb42" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true"></a>n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true"></a>nth_partial_sum <span class="op">=</span> (n <span class="op">*</span> (n <span class="op">+</span> <span class="dv">1</span>)) <span class="op">/</span> <span class="dv">2</span> </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true"></a>iterative_sum_count <span class="op">=</span> <span class="bu">sum</span>([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true"></a>contiguous_sublists <span class="op">=</span> <span class="kw">lambda</span> arr: [</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true"></a>    arr[m: n <span class="op">+</span> <span class="dv">1</span>] </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true"></a>    <span class="cf">for</span> m <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(arr)) </span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true"></a>    <span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(m, <span class="bu">len</span>(arr))</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true"></a>]</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true"></a>contiguous_sublist_count <span class="op">=</span> <span class="bu">len</span>(contiguous_sublists([<span class="dv">0</span>] <span class="op">*</span> n ))</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true"></a><span class="cf">assert</span> iterative_sum_count <span class="op">==</span> nth_partial_sum <span class="op">==</span> contiguous_sublist_count</span></code></pre></div>
<h3 id="derangement">Derangement</h3>
<p>A derangement is a permutation of the elements of a set such that no element appears in its original position. In other words, a derangement is a permutation that has no fixed points.</p>
<p><span class="math inline">\(!n\)</span> (<span class="math inline">\(n\)</span> subfactorial) is the number of derangements – <span class="math inline">\(n\)</span>-permutations where all of the n elements change their initial places. <span class="math display">\[!n=(n-1)({!(n-1)}+{!(n-2)})\]</span> <span class="math display">\[!n=n!\sum_{i=0}^{n}{\frac {(-1)^{i}}{i!}}\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb43" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true"></a><span class="im">import</span> random</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true"></a><span class="kw">def</span> random_derangement(n):</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true"></a>        v <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true"></a>            p <span class="op">=</span> random.randint(<span class="dv">0</span>, j)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true"></a>            <span class="cf">if</span> v[p] <span class="op">==</span> j:</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true"></a>                <span class="cf">break</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true"></a>            <span class="cf">else</span>:</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true"></a>                v[j], v[p] <span class="op">=</span> v[p], v[j]</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true"></a>        <span class="cf">else</span>:</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true"></a>            <span class="cf">if</span> v[<span class="dv">0</span>] <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true"></a>                <span class="cf">return</span> <span class="bu">tuple</span>(v)</span></code></pre></div>
<h3 id="fibonacci-numbers">Fibonacci Numbers</h3>
<p>A recursively defined sequence used to derive the golden ratio among other naturally occurring patterns and fractals.</p>
<p><span class="math display">\[F_{0}=0, \ F_{1}=1 \ \text{and} \ 
        F_{n}=F_{n-1}+F_{n-2} \ \text{for}  \ n &gt; 1.\]</span></p>
<p>The first few Fibonacci numbers are: <span class="math inline">\(0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \dots\)</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb44" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true"></a><span class="co"># Fibonacci series using Dynamic Programming  </span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true"></a><span class="kw">def</span> fibonacci(n):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true"></a>    <span class="cf">if</span> n <span class="op">&lt;=</span> <span class="dv">1</span>: <span class="cf">return</span> n</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true"></a>    dp <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>, n<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true"></a>        curr <span class="op">=</span> dp[<span class="dv">0</span>] <span class="op">+</span> dp[<span class="dv">1</span>]</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true"></a>        dp[<span class="dv">0</span>], dp[<span class="dv">1</span>] <span class="op">=</span> dp[<span class="dv">1</span>], curr</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true"></a>    <span class="cf">return</span> dp[<span class="dv">1</span>]</span></code></pre></div>
<h3 id="lattice-paths">Lattice Paths</h3>
<p>A sequence of ordered pairs <span class="math inline">\((m_1, n_1), (m_2, n_2), \cdots, (m_t, n_t)\)</span> such that a coordinate moves one unit either horizontally or vertically from its previous coordinate, i.e.:</p>
<ol type="1">
<li><p><span class="math inline">\(m_{i+1} = m_{i}+1\)</span> and <span class="math inline">\(n_{i+1} = n_{i}\)</span></p></li>
<li><p><span class="math inline">\(m_{i+1} = m_i\)</span> and <span class="math inline">\(n_{i+1} = n_i +1\)</span>.</p></li>
</ol>
<p>The construction of lattice paths forms a bijection with <span class="math inline">\(X\)</span>-strings where <span class="math inline">\(X = \{ H, V\}\)</span> with <span class="math inline">\(H,V\)</span> encoding horizontal or vertical moves on a grid. The number of lattice paths from <span class="math inline">\((m_1, n_1)\)</span> to <span class="math inline">\((m_2,n_2)\)</span> is, <span class="math display">\[\binom{m_2 - m_1 + m_2 - m_1}{m_2-m_1}.\]</span></p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb45" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true"></a><span class="im">import</span> math</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true"></a><span class="kw">def</span> unique_paths(m, n):</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true"></a>    <span class="cf">if</span> <span class="kw">not</span> m <span class="kw">or</span> <span class="kw">not</span> n: <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true"></a>    numerator <span class="op">=</span> math.factorial(m <span class="op">+</span> n <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true"></a>    denominator <span class="op">=</span> (math.factorial(n <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> math.factorial(m <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true"></a>    <span class="cf">return</span> numerator <span class="op">/</span> denominator</span></code></pre></div>
<h3 id="catalan-numbers">Catalan Numbers</h3>
<p>Catalan numbers are a sequence of natural numbers that occur in various counting problems,</p>
<ol type="1">
<li><p>The number of lattice paths from <span class="math inline">\((0, 0)\)</span> to <span class="math inline">\((n, n)\)</span> that do not go above the diagonal line <span class="math inline">\(y = x\)</span>.</p></li>
<li><p>Forming a bijection with up/down movements as characters <span class="math inline">\(X, Y\)</span>, shows that <span class="math inline">\(C_n\)</span> counts the number of Dyck words.</p></li>
<li><p>The number of valid arrangement of <span class="math inline">\(n\)</span> pairs of opening and closing parenthesis.</p></li>
<li><p>Re-interpreting the parenthesis as binary operators, i.e. associative multiplication orders, can count the number of possible orderings.</p></li>
<li><p>We may again re-interpret the binary operations count as being equivalent to the number of unique rooted full binary tree structures with n + 1 leaves.</p></li>
<li><p>The number of ways a convex polygon of <span class="math inline">\(n+2\)</span> sides can split into triangles by connecting vertices.</p></li>
</ol>
<p>Catalan number from binomial coefficients, <span class="math display">\[C(n) = \frac{1}{n+1}\binom{2n}{n}.\]</span></p>
<p>Catalan number from recursive definition, <span class="math display">\[C_0 = 1,\ \ C_{n+1} = \frac{2(2n+1)}{n+2} \cdot C_n.\]</span></p>
<p>The first few Catalan numbers are: <span class="math inline">\(1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796, 58786, \dots\)</span></p>
<p>The time complexity of brute-force computation of a Catalan number is <span class="math inline">\(\mathcal{O}(3^n)\)</span> which can be reduced to <span class="math inline">\(\mathcal{O}(2^n)\)</span> if recursive calls are memoized.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb46" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true"></a><span class="kw">def</span> catalan_recursive(n):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true"></a>    C <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n):</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true"></a>        C <span class="op">=</span> C <span class="op">*</span> <span class="dv">2</span><span class="op">*</span>(<span class="dv">2</span><span class="op">*</span>i<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>(i<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true"></a>    <span class="cf">return</span> <span class="bu">int</span>(C)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true"></a>    </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true"></a><span class="kw">def</span> catalan_dp(n): </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true"></a>    <span class="cf">if</span> n <span class="op">&lt;=</span> <span class="dv">1</span>: <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true"></a>    dp <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> (n <span class="op">+</span> <span class="dv">1</span>) </span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true"></a>    dp[<span class="dv">0</span>] <span class="op">=</span> dp[<span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, n <span class="op">+</span> <span class="dv">1</span>): </span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true"></a>        dp[i] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i): </span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true"></a>            dp[i] <span class="op">=</span> dp[i] <span class="op">+</span> dp[j] <span class="op">*</span> dp[i<span class="op">-</span>j<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true"></a>    <span class="cf">return</span> dp[n]</span></code></pre></div>
<h3 id="stars-and-bars">Stars and Bars</h3>
<p>The number of ways to put <span class="math inline">\(n\)</span> identical objects into <span class="math inline">\(k\)</span> labeled boxes is, <span class="math display">\[\binom{n+k-1}{n}.\]</span></p>
<p>We can use this for various counting problems, i.e the number of non-negative integer sums, the number of lower-bound integer sums, etc.</p>
<p><em>Python Implementation</em></p>
<div class="sourceCode" id="cb47" data-language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true"></a><span class="im">import</span> itertools</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true"></a><span class="kw">def</span> stars_and_bars(n, k):</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true"></a>    <span class="cf">for</span> c <span class="kw">in</span> itertools.combinations(<span class="bu">range</span>(n <span class="op">+</span> k <span class="op">-</span> <span class="dv">1</span>), k <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true"></a>        <span class="cf">yield</span> [b <span class="op">-</span> a <span class="op">-</span> <span class="dv">1</span> <span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>((<span class="op">-</span><span class="dv">1</span>,) <span class="op">+</span> c, c <span class="op">+</span> ( n <span class="op">+</span> k <span class="op">-</span> <span class="dv">1</span>,))]</span></code></pre></div>
<h1 id="appendix">Appendix</h1>
<h2 id="powers-of-2-table">Powers of 2 Table</h2>
<figure>
<img src="powers-of-two.png" style="width:10cm" alt="" /><figcaption>image</figcaption>
</figure>
<h2 id="array-sorting-algorithms-table">Array Sorting Algorithms Table</h2>
<figure>
<img src="Array_sorting_algorithms.png" style="width:13cm" alt="" /><figcaption>image</figcaption>
</figure>
<h2 id="single-source-shortest-path-table">Single-Source Shortest Path Table</h2>
<h2 id="algorithm-optimization-checklist">Algorithm Optimization Checklist</h2>
<ol type="1">
<li><p>Consider Best Conceivable Runtime (BCR). Try to derive an approach from an ideal upper bound on the solution.</p></li>
<li><p>Consider making a time-space trade off, usually in the form of a hash-table or cached results.</p></li>
<li><p>Data Structure Brainstorm. Linked List, Stack, Queue, Priority Queue, Heap, Dictionary, Set, Binary tree, Graph, etc.</p></li>
<li><p>Simplify and Generalize. Simplify problem statement then attempt to generalize solution to original problem.</p></li>
<li><p>Look for BUD (bottlenecks, unnecessary work, duplicated work).</p></li>
<li><p>DIY (Do It Yourself). Design an algorithm around how you would solve an analogous real-word scenario without programming.</p></li>
</ol>
<h2 id="whiteboard-interview-checklist">Whiteboard Interview Checklist</h2>
<ol type="1">
<li><p>Restate and reduce problem</p>
<ol type="1">
<li><p>Carefully read the problem. If constraints on input are given, be sure to make a mental note of them.</p></li>
<li><p>Spend some time simplifying and re-stating problem in your own words. This helps solidify your understanding, plus translating the problem into its most essential form may reveal possible reductions.</p></li>
<li><p>What are problematic or challenging areas that might arise from certain inputs? For example, an input that causes a naive approach to traverse the decision tree toward an incorrect solution. These inputs can be converted into sufficiently complex test cases later.</p></li>
<li><p>Can you pre-process the input or re-interpret the desired output to simplify or reduce the problem? This may involve sorting a sequence, converting a matrix to a graph, etc.</p></li>
<li><p>What is the best conceivable run time? If it’s not yet obvious, this can be examined later during the optimization phase.</p></li>
<li><p>What are your intuitions about possible solutions? You can revisit these ideas later.</p></li>
</ol></li>
<li><p>State brute-force solution</p>
<ol type="1">
<li><p>Give an overview of the approach.</p></li>
<li><p>Find the time and space complexity.</p></li>
<li><p>If you don’t have any immediate ideas for an optimized solution, spend time elaborating on the brute force algorithm, otherwise mention that we can do better and can move on.</p></li>
</ol></li>
<li><p>Optimize previous approach or introduce new, better approach</p>
<ol type="1">
<li><p>Brainstorm using Algorithm Optimization Checklist. Avoid getting stuck on memory recall for too long, even you recognize the problem.</p></li>
<li><p>Give an overview of the approach.</p></li>
<li><p>Find the time and space complexity.</p></li>
<li><p>Repeat or expand. Always spend extra time considering alternative approaches before implementing a solution.</p></li>
<li><p>When out of ideas or if able to match the best conceivable run time with low/linear space complexity, prompt the interviewer for approval: “If you’re happy with this approach, I can go into the finer details and begin implemention”</p></li>
</ol></li>
<li><p>Consider more granular implementation details</p>
<ol type="1">
<li><p>Describe edge cases, i.e. empty input, invalid inputs, large inputs.</p></li>
<li><p>Consider boundary conditions if dealing with iterations, indexed arrays, or ranges.</p></li>
<li><p>Describe sufficiently complex test case if none are given, consider problem areas.</p></li>
<li><p>Consider minor optimizations to general approach, i.e. short-circuiting, more performant data structures, caching.</p></li>
<li><p>If using recursion, note the limitations of relying on the call stack.</p></li>
</ol></li>
<li><p>Implement</p>
<ol type="1">
<li><p>Speak aloud your thinking process, even when stuck.</p></li>
<li><p>Handle base/empty cases, i.e. empty inputs, invalid input error checks.</p></li>
<li><p>Use descriptive variable and function names.</p></li>
<li><p>Add inline comments when necessary.</p></li>
<li><p>Do not repeat yourself (DRY).</p></li>
<li><p>Use modular code when possible.</p></li>
<li><p>Follow coding principles (Correct, Efficient, Simple, Readable, Maintainable).</p></li>
</ol></li>
<li><p>Validate and test with dry runs</p>
<ol type="1">
<li><p>Scan over code and double check for any syntax errors.</p></li>
<li><p>Walk through code using sufficiently complex test cases.</p></li>
<li><p>Ensure boundary conditions don’t cause errors.</p></li>
<li><p>Clean up code if possible.</p></li>
</ol></li>
<li><p>Re-state final analysis</p>
<ol type="1">
<li><p>State time and space complexity of implementation.</p></li>
<li><p>Consider further optimizations if time complexity is not BCR and space complexity is not constant.</p></li>
</ol></li>
</ol>
<p>Steven S. Skiena. 2008. The Algorithm Design Manual (2nd. ed.). Springer Publishing Company, Incorporated.</p>
<p>Erik Demaine, Srini Devadas. Introduction to Algorithms. Fall 2011. Massachusetts Institute of Technology: MIT OpenCouseWare, https://ocw.mit.edu/. License: Creative Commons</p>
<p>David Liu, Data Structures and Analysis: Lecture Notes for CSC263, Department of Computer Science, University of Toronto</p>
<p>McDowell, Gayle Laakmann, Cracking The Coding Interview: 150 Programming Questions and Solutions. Palo Alto, CA :CareerCup, LLC, 2011.</p>
<p>Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2009. Introduction to Algorithms, Third Edition (3rd. ed.). The MIT Press.</p>
<p>Keller, M.T. and Trotter, W.T., Applied Combinatorics, Open Textbook Library,</p>
<p>ISBN9781534878655</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://leetcode.com/problems/subarrays-with-k-different-integers/<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://leetcode.com/problems/longest-continuous-subarray-with-absolute-diff-less-than-or-equal-to-limit/<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://github.com/lukepereira/latex-ci<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
